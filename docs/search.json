[
  {
    "objectID": "01-geodemographics.html",
    "href": "01-geodemographics.html",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "This week we will turn to geodemographic classification. Geodemographic classification is a method used to categorise geographic areas and the people living in them based on demographic, socioeconomic, and sometimes lifestyle characteristics. This approach combines geographic information with demographic data to create profiles of different neighborhoods.\n\n\nYou can download the slides of this week’s lecture here: [Link].\n\n\n\n\n\n\nLongley, P. A. 2012. Geodemographics and the practices of geographic information science. International Journal of Geographical Information Science 26(12): 2227-2237. [Link]\nSingleton, A. and Longley, P. A. 2024. Classifying and mapping residential structure through the London Output Area Classification. Environment and Planning B: Urban Analytics and City Science 51(5): 1153-1164. [Link]\nWyszomierski, J., Longley, P. A., and Singleton, A. et al. 2024. A neighbourhood Output Area Classification from the 2021 and 2022 UK censuses. The Geographical Journal. 190(2): e12550. [Link]\n\n\n\n\n\nFränti, P. and Sieronoja, S. 2019. How much can k-means be improved by using better initialization and repeats? Pattern Recognition 93: 95-112. [Link]\nSingleton, A. and Spielman, S. 2014. The past, present, and future of geodemographic research in the United States and United Kingdom. The Professional Geographer 66(4): 558-567. [Link]\n\n\n\n\n\nToday, we will create our own geodemographic classification to examine demographic clusters across London, drawing inspiration from London Output Area Classification. Specifically, we will try to identify clusters based on age group, self-identified ethnicity, country of birth, and first or preferred language.\nThe data covers all usual residents, as recorded in the 2021 Census for England and Wales, aggregated at the Lower Super Output Area (LSOA) level. These datasets have been extracted using the Custom Dataset Tool, and you can download each file via the links provided below. A copy of the 2021 London LSOAs spatial boundaries is also available. Save these files in your project folder under data.\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon LSOA Census 2021 Age Groups\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Country of Birth\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Ethnicity\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Main Language\ncsv\nDownload\n\n\nLondon LSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\n\n\n\n\nTo download a csv file that is hosted on GitHub, click on the Download raw file button on the top right of your screen and it should download directly to your computer.\n\n\n\n\n\n\n\n\n\nFor the spatial boundaries of the London LSOAs, you may have noticed that, instead of providing a collection of files known as a shapefile, we have supplied a GeoPackage. While shapefiles remain in use, GeoPackage is a more modern and portable file format. Have a look at this article on towardsdatascience.com for an excellent explanation on why one should use GeoPackage files over shapefiles, where possible: [Link]\n\n\n\nOpen a new script and save this as w07-geodemographics.r. Begin by loading the necessary libraries:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggcorrplot)\nlibrary(cluster)\nlibrary(factoextra)\nlibrary(sf)\nlibrary(tmap)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nNext, we can load the individual csv files that we downloaded into R.\n\n\n\nR code\n\n# load age data\nlsoa_age &lt;- read_csv(\"data/London-LSOA-AgeGroup.csv\")\n\n\nRows: 24970 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Age (5 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load country of birth data\nlsoa_cob &lt;- read_csv(\"data/London-LSOA-Country-of-Birth.csv\")\n\nRows: 39952 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Country of birth (8 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load ethnicity data\nlsoa_eth &lt;- read_csv(\"data/London-LSOA-Ethnicity.csv\")\n\nRows: 99880 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Ethnic group (20 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load language data\nlsoa_lan &lt;- read_csv(\"data/London-LSOA-MainLanguage.csv\")\n\nRows: 54934 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Main language (11 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nIf using a Windows machine, you may need to substitute your forward-slashes (/) with two backslashes (\\\\) whenever you are dealing with file paths.\n\n\n\nNow, carefully examine each individual dataframe to understand how the data is structured and what information it contains.\n\n\n\nR code\n\n# inspect age data\nhead(lsoa_age)\n\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Age (5 categories) C…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                         1\n2 E01000001                        City of London 001A                         2\n3 E01000001                        City of London 001A                         3\n4 E01000001                        City of London 001A                         4\n5 E01000001                        City of London 001A                         5\n6 E01000002                        City of London 001B                         1\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Age (5 categories) Code`\n# ℹ 2 more variables: `Age (5 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n# inspect country of birth data\nhead(lsoa_cob)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Country of birth (8 …³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Country of birth (8 categories) Code`\n# ℹ 2 more variables: `Country of birth (8 categories)` &lt;chr&gt;,\n#   Observation &lt;dbl&gt;\n\n# inspect ethnicity data\nhead(lsoa_eth)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Ethnic group (20 cat…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Ethnic group (20 categories) Code`\n# ℹ 2 more variables: `Ethnic group (20 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n# inspect language data\nhead(lsoa_lan)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Main language (11 ca…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Main language (11 categories) Code`\n# ℹ 2 more variables: `Main language (11 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\n\n\nTo identify geodemographic clusters in our dataset, we will use a technique called \\(k\\)-means. \\(k\\)-means aims to partition a set of standardised observations into a specified number of clusters (\\(k\\)). To do this we first need to prepare the individual datasets, as well as transform and standardise the input variables.\n\n\n\n\n\n\n\\(k\\)-means clustering is an unsupervised machine learning algorithm used to group data into a predefined number of clusters, based on similarities between data points. It works by initially assigning \\(k\\) random centroids, then iteratively updating them by assigning each data point to the nearest centroid and recalculating the centroid’s position based on the mean of the points in each cluster. The process continues until the centroids stabilise, meaning they no longer change significantly. \\(k\\)-means is often used for tasks such as data segmentation, image compression, or anomaly detection. It is simple but may not work well with non-spherical or overlapping clusters.\n\n\n\nBecause all the data are stored in long format, with each London LSOA appearing on multiple rows for each category — such as separate rows for different age groups, ethnicities, countries of birth, and first or preferred languages - we need to transform it into a wide format. For example, instead of having multiple rows for an LSOA showing counts for different age groups all the information for each LSOA will be consolidated into a single row. Additionally, we will clean up the column names to follow standard R naming conventions and make the data easier to work with. We can automate this process using the janitor package.\nWe will begin with the age dataframe:\n\n\n\nR code\n\n# clean names\nlsoa_age &lt;- lsoa_age |&gt;\n    clean_names()\n\n# pivot\nlsoa_age &lt;- lsoa_age |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"age_5_categories\",\n        values_from = \"observation\")\n\n# clean names\nlsoa_age &lt;- lsoa_age |&gt;\n    clean_names()\n\n\n\n\n\n\n\n\nThe code above uses a pipe function: |&gt;. The pipe operator allows you to pass the output of one function directly into the next, streamlining your code. While it might be a bit confusing at first, you will find that it makes your code faster to write and easier to read. More importantly, it reduces the need to create multiple intermediate variables to store outputs.\n\n\n\nTo account for the non-uniformity of the areal units, we further need to convert the observations to percentages and only retain those columns that are likely to be meaningful in the context of the classification:\n\n\n\nR code\n\n# total observations\nlsoa_age &lt;- lsoa_age |&gt;\n    rowwise() |&gt;\n    mutate(age_pop = sum(across(2:6)))\n\n# total proportions, select columns\nlsoa_age &lt;- lsoa_age |&gt;\n    mutate(across(2:6, ~./age_pop)) |&gt;\n    select(1:6)\n\n# inspect\nhead(lsoa_age)\n\n\n# A tibble: 6 × 6\n# Rowwise: \n  lower_layer_super_output_areas_code aged_15_years_and_un…¹ aged_16_to_24_years\n  &lt;chr&gt;                                                &lt;dbl&gt;               &lt;dbl&gt;\n1 E01000001                                           0.0846              0.0744\n2 E01000002                                           0.0621              0.0889\n3 E01000003                                           0.0682              0.0706\n4 E01000005                                           0.127               0.178 \n5 E01000006                                           0.224               0.120 \n6 E01000007                                           0.257               0.103 \n# ℹ abbreviated name: ¹​aged_15_years_and_under\n# ℹ 3 more variables: aged_25_to_34_years &lt;dbl&gt;, aged_35_to_49_years &lt;dbl&gt;,\n#   aged_50_years_and_over &lt;dbl&gt;\n\n\nThis looks much better. We can do the same for the country of birth data:\n\n\n\nR code\n\n# prepare country of birth data\nlsoa_cob &lt;- lsoa_cob |&gt;\n    clean_names() |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"country_of_birth_8_categories\",\n        values_from = \"observation\") |&gt;\n    clean_names()\n\n# proportions, select columns\nlsoa_cob &lt;- lsoa_cob |&gt;\n    rowwise() |&gt;\n    mutate(cob_pop = sum(across(2:9))) |&gt;\n    mutate(across(2:9, ~./cob_pop)) |&gt;\n    select(-2, -10)\n\n\nAnd we can do the same for the ethnicity and language datasets:\n\n\n\nR code\n\n# prepare ethnicity data\nlsoa_eth &lt;- lsoa_eth |&gt;\n    clean_names() |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"ethnic_group_20_categories\",\n        values_from = \"observation\") |&gt;\n    clean_names()\n\n# proportions, select columns\nlsoa_eth &lt;- lsoa_eth |&gt;\n    rowwise() |&gt;\n    mutate(eth_pop = sum(across(2:21))) |&gt;\n    mutate(across(2:21, ~./eth_pop)) |&gt;\n    select(-2, -22)\n\n# prepare language data\nlsoa_lan &lt;- lsoa_lan |&gt;\n    clean_names() |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"main_language_11_categories\",\n        values_from = \"observation\") |&gt;\n    clean_names()\n\n# proportions, select columns\nlsoa_lan &lt;- lsoa_lan |&gt;\n    rowwise() |&gt;\n    mutate(lan_pop = sum(across(2:12))) |&gt;\n    mutate(across(2:12, ~./lan_pop)) |&gt;\n    select(-2, -11, -13)\n\n\nWe now have four separate datasets, each containing the proportions of usual residents classified into different groups based on age, country of birth, ethnicity, and language.\n\n\n\nWhere we initially selected variables from different demographic domains, not all variables may be suitable for inclusion. Firstly, the variables need to exhibit sufficient heterogeneity to ensure they capture meaningful differences between observations. Secondly, variables should not be highly correlated with one another, as this redundancy can skew the clustering results. Ensuring acceptable correlation between variables helps maintain the diversity of information and improves the robustness of the clustering outcome.\n\n\n\n\n\n\nVariable selection is often a time-consuming process that requires a combination of domain knowledge and more extensive exploratory analysis than is covered in this practical.\n\n\n\nA straightforward yet effective method to examine the distribution of our variables is to create boxplots for each variable. This can be efficiently achieved by using facet_wrap() to generate a matrix of panels, allowing us to visualise all variables in a single view.\n\n\n\n\n\n\nFor more details on facet_wrap(), you can refer to the ggplot2 documentation.\n\n\n\n\n\n\nR code\n\n# wide to long\nlsoa_age_wd &lt;- lsoa_age |&gt;\n    pivot_longer(cols = c(2:5), names_to = \"agegroup\", values_to = \"count\")\n\n# facet age\nggplot(lsoa_age_wd, aes(y = count)) + geom_boxplot() + facet_wrap(~agegroup, ncol = 2) +\n    theme_minimal() + ylab(\"\")\n\n\n\n\n\nFigure 1: Boxplots of the distribution of the age dataset.\n\n\n\n\nWhen repeating this process for the birth, ethnicity, and language variables, you will notice that some variables have a very limited distribution. Specifically, some variables may have a value of 0 for the majority of London LSOAs. As a rule of thumb, we will retain only those variables where at least 75% of the LSOAs have values different from 0.\n\n\n\n\n\n\nThis threshold of 75% is arbitrary, and in practice, more thorough consideration should be given when deciding whether to include or exclude a variable.\n\n\n\n\n\n\nR code\n\n# join\nlsoa_df &lt;- lsoa_age |&gt;\n    left_join(lsoa_cob, by = \"lower_layer_super_output_areas_code\") |&gt;\n    left_join(lsoa_eth, by = \"lower_layer_super_output_areas_code\") |&gt;\n    left_join(lsoa_lan, by = \"lower_layer_super_output_areas_code\")\n\n# calculate proportion of zeroes\nzero_prop &lt;- sapply(lsoa_df[2:41], function(x) {\n    mean(x == 0)\n})\n\n# extract variables with high proportion zeroes\nidx &lt;- which(zero_prop &gt; 0.25)\n\n# inspect\nidx\n\n\n   white_gypsy_or_irish_traveller            any_other_uk_languages \n                               27                                33 \n  oceanic_or_australian_languages north_or_south_american_languages \n                               37                                38 \n\n# remove variables with high proportion zeroes\nlsoa_df &lt;- lsoa_df |&gt;\n    select(-white_gypsy_or_irish_traveller, -any_other_uk_languages, -oceanic_or_australian_languages,\n        -north_or_south_american_languages)\n\n\n\n\n\n\n\nThe code above makes use of Boolean logic to calculate the proportion of zeroes within each variable. The x == 0 part checks each value in column x to see if it is equal to 0, returning TRUE or FALSE for each element. The mean() function is then used to calculate the average of the TRUE values in the column. Since TRUE is treated as 1 and FALSE as 0, this gives the proportion of values in the column that are equal to zero.\n\n\n\nWe can subsequently check for multicollinearity of the remaining variables. The easiest way to check the correlations between all variables is probably by visualising a correlation matrix:\n\n\n\nR code\n\n# inspect variable names\nnames(lsoa_df)\n\n\n [1] \"lower_layer_super_output_areas_code\"                                  \n [2] \"aged_15_years_and_under\"                                              \n [3] \"aged_16_to_24_years\"                                                  \n [4] \"aged_25_to_34_years\"                                                  \n [5] \"aged_35_to_49_years\"                                                  \n [6] \"aged_50_years_and_over\"                                               \n [7] \"europe_united_kingdom\"                                                \n [8] \"europe_ireland\"                                                       \n [9] \"europe_other_europe\"                                                  \n[10] \"africa\"                                                               \n[11] \"middle_east_and_asia\"                                                 \n[12] \"the_americas_and_the_caribbean\"                                       \n[13] \"antarctica_and_oceania_including_australasia_and_other\"               \n[14] \"asian_asian_british_or_asian_welsh_bangladeshi\"                       \n[15] \"asian_asian_british_or_asian_welsh_chinese\"                           \n[16] \"asian_asian_british_or_asian_welsh_indian\"                            \n[17] \"asian_asian_british_or_asian_welsh_pakistani\"                         \n[18] \"asian_asian_british_or_asian_welsh_other_asian\"                       \n[19] \"black_black_british_black_welsh_caribbean_or_african_african\"         \n[20] \"black_black_british_black_welsh_caribbean_or_african_caribbean\"       \n[21] \"black_black_british_black_welsh_caribbean_or_african_other_black\"     \n[22] \"mixed_or_multiple_ethnic_groups_white_and_asian\"                      \n[23] \"mixed_or_multiple_ethnic_groups_white_and_black_african\"              \n[24] \"mixed_or_multiple_ethnic_groups_white_and_black_caribbean\"            \n[25] \"mixed_or_multiple_ethnic_groups_other_mixed_or_multiple_ethnic_groups\"\n[26] \"white_english_welsh_scottish_northern_irish_or_british\"               \n[27] \"white_irish\"                                                          \n[28] \"white_roma\"                                                           \n[29] \"white_other_white\"                                                    \n[30] \"other_ethnic_group_arab\"                                              \n[31] \"other_ethnic_group_any_other_ethnic_group\"                            \n[32] \"english_or_welsh\"                                                     \n[33] \"european_languages_eu\"                                                \n[34] \"other_european_languages_non_eu\"                                      \n[35] \"asian_languages\"                                                      \n[36] \"african_languages\"                                                    \n[37] \"any_other_languages\"                                                  \n\n# change variable names to index to improve visualisation\nlsoa_df_vis &lt;- lsoa_df\nnames(lsoa_df_vis)[2:37] &lt;- paste0(\"v\", sprintf(\"%02d\", 1:36))\n\n# correlation matrix\ncor_mat &lt;- cor_pmat(lsoa_df_vis[, -1])\n\n# correlation plot\nggcorrplot(cor_mat, hc.order = FALSE, outline.col = \"#ffffff\", tl.cex = 8)\n\n\n\n\nFigure 2: Correlation plot of classification variables.\n\n\n\n\nFollowing the approach from Wyszomierski et al. (2024), we can define a weak correlation as lying between 0 and 0.40, moderate as between 0.41 and 0.65, strong as between 0.66 and 0.80, and very strong as between 0.81 and 1.\nA few strong and very strong correlations can be observed that probably should be removed; however, to maintain representation, here we decide to retain all variables.\n\n\n\nIf the input data are heavily skewed or contain outliers, \\(k\\)-means may produce less meaningful clusters. While normality is not required per se, it has been common to do this nonetheless. More important is to standardise the input variables, especially when they are measured on different scales. This ensures that each variable contributes equally to the clustering process.\n\n\n\nR code\n\n# inverse hyperbolic sine\nlsoa_df_vis[, -1] &lt;- sapply(lsoa_df_vis[-1], asinh)\n\n# range standardise\nlsoa_df_vis[, -1] &lt;- sapply(lsoa_df_vis[-1], function(x) {\n    (x - min(x))/(max(x) - min(x))\n})\n\n\n\n\n\nNow our data are prepared we will start by creating an elbow plot. The elbow method is a visual tool that helps determine the optimal number of clusters in a dataset. This is important because with \\(k\\)-means clustering you need to specify the numbers of clusters a priori. The elbow method involves running the clustering algorithm with varying numbers of clusters (\\(k\\)) and plotting the total explained variation (known as the Within Sum of Squares) against the number of clusters. The goal is to identify the ‘elbow’ point on the curve, where the rate of decrease in explained variation starts to slow. This point suggests that adding more clusters yields diminishing returns in terms of explained variation.\n\n\n\nR code\n\n# elbow plot\nfviz_nbclust(lsoa_df_vis[, -1], kmeans, nstart = 100, iter.max = 100, method = \"wss\")\n\n\n\n\n\nFigure 3: Elbow plot with ‘Within Sum of Squares’ against number of clusters.\n\n\n\n\nBased on the elbow plot, we can now choose the number of clusters and it looks like 6 clusters would be a reasonable choice.\n\n\n\n\n\n\nThe interpretation of an elbow plot can be quite subjective, and multiple options for the optimal number of clusters might be justified; for instance, 4, 5, or even 7 clusters could be reasonable choices. In addition to the elbow method, other techniques can aid in determining the optimal number of clusters, such as silhouette scores and the gap statistic. An alternative and helful approach is to use a clustergram, which is a two-dimensional plot that visualises the flows of observations between clusters as more clusters are added. This method illustrates how your data reshuffles with each additional cluster and provides insights into the quality of the splits. This method can be done in R, but currently easier to implement in Python.\n\n\n\n\n\n\nNow we have decided on the number of clusters, we can run our \\(k\\)-means analysis.\n\n\n\nR code\n\n# set seed for reproducibility\nset.seed(999)\n\n# k-means\nlsoa_clus &lt;- kmeans(lsoa_df_vis[, -1], centers = 6, nstart = 100, iter.max = 100)\n\n\nWe can inspect the object to get some information about our clusters:\n\n\n\nR code\n\n# inspect\nlsoa_clus\n\n\nK-means clustering with 6 clusters of sizes 796, 1097, 771, 1011, 851, 468\n\nCluster means:\n        v01       v02       v03       v04       v05       v06       v07\n1 0.4816225 0.1632210 0.2425566 0.4838983 0.4169123 0.5410477 0.1337158\n        v08       v09       v10        v11        v12        v13        v14\n1 0.3007540 0.2480613 0.2859754 0.08913663 0.05177222 0.14603013 0.06993627\n         v15        v16        v17        v18        v19        v20        v21\n1 0.12176548 0.10935022 0.20109979 0.18150482 0.11605092 0.12757934 0.09288236\n         v22        v23       v24       v25       v26        v27       v28\n1 0.07473711 0.14662903 0.1842217 0.3522638 0.1490577 0.02997040 0.2423784\n         v29       v30       v31       v32        v33        v34        v35\n1 0.07148504 0.2193009 0.5870244 0.2411272 0.07541661 0.23467242 0.10174187\n         v36\n1 0.10216507\n [ reached getOption(\"max.print\") -- omitted 5 rows ]\n\nClustering vector:\n [1] 4 4 4 1 1 5 5 6 6 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 2 2 1 1 2 2 2 1 1 1\n[39] 1 1 1 1 5 1 5 1 1 1 1 1\n [ reached getOption(\"max.print\") -- omitted 4944 entries ]\n\nWithin cluster sum of squares by cluster:\n[1] 259.0272 177.7951 288.8625 232.7770 298.9145 160.1702\n (between_SS / total_SS =  48.5 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\n\n\nWe now need to perform some post-processing to extract useful summary data for each cluster. To characterise the clusters, we can compare the global mean values of each variable with the mean values specific to each cluster.\n\n\n\nR code\n\n# global means\nglob_means &lt;- colMeans(lsoa_df_vis[, -1])\n\n# add clusters to input data\nlsoa_df_vis &lt;- cbind(lsoa_df_vis, cluster = lsoa_clus$cluster)\n\n# cluster means\ncluster_means &lt;- lsoa_df_vis |&gt;\n    group_by(cluster) |&gt;\n    summarise(across(2:37, mean))\n\n# difference\ncluster_diffs &lt;- cluster_means |&gt;\n    mutate(across(2:37, ~. - glob_means[cur_column()]))\n\n\nThese comparisons can then be visualised using, for instance, a radial bar plot:\n\n\n\nR code\n\n# to long format\ncluster_diffs_long &lt;- cluster_diffs |&gt;\n    pivot_longer(!cluster, names_to = \"vars\", values_to = \"score\")\n\n# facet clusters\nggplot(cluster_diffs_long, aes(x = factor(vars), y = score)) + geom_bar(stat = \"identity\") +\n    coord_radial(rotate.angle = TRUE, expand = FALSE) + facet_wrap(~cluster, ncol = 3) +\n    theme_minimal() + xlab(\"\") + ylab(\"\")\n\n\n\n\n\nFigure 4: Radial barplots of cluster means for each input variable.\n\n\n\n\nThese plots can serve as a foundation for creating pen portraits by closely examining which variables drive each cluster.\n\n\n\n\n\n\nFor easier interpretation, these values can be transformed into index scores, allowing us to assess which variables are under- or overrepresented within each cluster group.\n\n\n\nOf course, we can also map the results:\n\n\n\nR code\n\n# read spatial dataset\nlsoa21 &lt;- st_read(\"data/London-LSOA-2021.gpkg\")\n\n\nReading layer `LSOA2021_London' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0114/data/London-LSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 4994 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# join\nlsoa21 &lt;- cbind(lsoa21, cluster = lsoa_clus$cluster)\n\n# shape, polygon\ntm_shape(lsoa21) +\n\n  # specify column, colours\n  tm_polygons(\n    col = \"cluster\",\n    palette = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n    border.col = \"#ffffff\",\n    border.alpha = 0.1,\n    title = \"Cluster number\"\n  ) +\n\n  # set layout\n  tm_layout(\n    legend.outside = FALSE,\n    legend.position = c(\"right\", \"bottom\"),\n    frame = FALSE\n  )\n\n\n\n\nFigure 5: Classification of London LSOAs based on several demographic variables.\n\n\n\n\n\n\n\n\nThe creation of a geodemographic classification is an iterative process. This typically includes adding or removing variables, adjusting the number of clusters, and grouping data in different ways to achieve the most meaningful segmentation. Try to do the following:\n\nDownload the two datasets provided below and save them to your data folder. The datasets include:\n\nA csv file containing the number of people aged 16 years and older by occupational category, as defined by the Standard Occupational Classification 2020, aggregated by 2021 LSOAs.\nA csv file containing the number of people aged 16 years and older by their highest level of qualification, also aggregated to the LSOA level.\n\nPrepare these two datasets and retain only those variables that are potentially meaningful. Filter out any variables with a high proportion of zero values.\nMerge the education and occupation dataset with the dataset used to generate the initial geodemographic classification. Check for multicollinearity and consider removing any variables that are highly correlated.\nPerform \\(k\\)-means clustering on your extended dataset. Make sure to select an appropriate number of clusters for your analysis.\nInterpret the individual clusters in terms of the variables that are under- or overrepresented.\n\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon LSOA Census 2021 Occupation\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Education\ncsv\nDownload\n\n\n\n\n\n\nHaving finished this tutorial, you should now understand the basics of a geodemographic classification. That is all for this week!"
  },
  {
    "objectID": "01-geodemographics.html#lecture-w07",
    "href": "01-geodemographics.html#lecture-w07",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "You can download the slides of this week’s lecture here: [Link]."
  },
  {
    "objectID": "01-geodemographics.html#reading-w07",
    "href": "01-geodemographics.html#reading-w07",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "Longley, P. A. 2012. Geodemographics and the practices of geographic information science. International Journal of Geographical Information Science 26(12): 2227-2237. [Link]\nSingleton, A. and Longley, P. A. 2024. Classifying and mapping residential structure through the London Output Area Classification. Environment and Planning B: Urban Analytics and City Science 51(5): 1153-1164. [Link]\nWyszomierski, J., Longley, P. A., and Singleton, A. et al. 2024. A neighbourhood Output Area Classification from the 2021 and 2022 UK censuses. The Geographical Journal. 190(2): e12550. [Link]\n\n\n\n\n\nFränti, P. and Sieronoja, S. 2019. How much can k-means be improved by using better initialization and repeats? Pattern Recognition 93: 95-112. [Link]\nSingleton, A. and Spielman, S. 2014. The past, present, and future of geodemographic research in the United States and United Kingdom. The Professional Geographer 66(4): 558-567. [Link]"
  },
  {
    "objectID": "01-geodemographics.html#clusters-in-london",
    "href": "01-geodemographics.html#clusters-in-london",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "Today, we will create our own geodemographic classification to examine demographic clusters across London, drawing inspiration from London Output Area Classification. Specifically, we will try to identify clusters based on age group, self-identified ethnicity, country of birth, and first or preferred language.\nThe data covers all usual residents, as recorded in the 2021 Census for England and Wales, aggregated at the Lower Super Output Area (LSOA) level. These datasets have been extracted using the Custom Dataset Tool, and you can download each file via the links provided below. A copy of the 2021 London LSOAs spatial boundaries is also available. Save these files in your project folder under data.\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon LSOA Census 2021 Age Groups\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Country of Birth\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Ethnicity\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Main Language\ncsv\nDownload\n\n\nLondon LSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\n\n\n\n\n\n\n\nTo download a csv file that is hosted on GitHub, click on the Download raw file button on the top right of your screen and it should download directly to your computer.\n\n\n\n\n\n\n\n\n\nFor the spatial boundaries of the London LSOAs, you may have noticed that, instead of providing a collection of files known as a shapefile, we have supplied a GeoPackage. While shapefiles remain in use, GeoPackage is a more modern and portable file format. Have a look at this article on towardsdatascience.com for an excellent explanation on why one should use GeoPackage files over shapefiles, where possible: [Link]\n\n\n\nOpen a new script and save this as w07-geodemographics.r. Begin by loading the necessary libraries:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggcorrplot)\nlibrary(cluster)\nlibrary(factoextra)\nlibrary(sf)\nlibrary(tmap)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nNext, we can load the individual csv files that we downloaded into R.\n\n\n\nR code\n\n# load age data\nlsoa_age &lt;- read_csv(\"data/London-LSOA-AgeGroup.csv\")\n\n\nRows: 24970 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Age (5 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load country of birth data\nlsoa_cob &lt;- read_csv(\"data/London-LSOA-Country-of-Birth.csv\")\n\nRows: 39952 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Country of birth (8 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load ethnicity data\nlsoa_eth &lt;- read_csv(\"data/London-LSOA-Ethnicity.csv\")\n\nRows: 99880 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Ethnic group (20 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load language data\nlsoa_lan &lt;- read_csv(\"data/London-LSOA-MainLanguage.csv\")\n\nRows: 54934 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Main language (11 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nIf using a Windows machine, you may need to substitute your forward-slashes (/) with two backslashes (\\\\) whenever you are dealing with file paths.\n\n\n\nNow, carefully examine each individual dataframe to understand how the data is structured and what information it contains.\n\n\n\nR code\n\n# inspect age data\nhead(lsoa_age)\n\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Age (5 categories) C…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                         1\n2 E01000001                        City of London 001A                         2\n3 E01000001                        City of London 001A                         3\n4 E01000001                        City of London 001A                         4\n5 E01000001                        City of London 001A                         5\n6 E01000002                        City of London 001B                         1\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Age (5 categories) Code`\n# ℹ 2 more variables: `Age (5 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n# inspect country of birth data\nhead(lsoa_cob)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Country of birth (8 …³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Country of birth (8 categories) Code`\n# ℹ 2 more variables: `Country of birth (8 categories)` &lt;chr&gt;,\n#   Observation &lt;dbl&gt;\n\n# inspect ethnicity data\nhead(lsoa_eth)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Ethnic group (20 cat…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Ethnic group (20 categories) Code`\n# ℹ 2 more variables: `Ethnic group (20 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n# inspect language data\nhead(lsoa_lan)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Main language (11 ca…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Main language (11 categories) Code`\n# ℹ 2 more variables: `Main language (11 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\n\n\nTo identify geodemographic clusters in our dataset, we will use a technique called \\(k\\)-means. \\(k\\)-means aims to partition a set of standardised observations into a specified number of clusters (\\(k\\)). To do this we first need to prepare the individual datasets, as well as transform and standardise the input variables.\n\n\n\n\n\n\n\\(k\\)-means clustering is an unsupervised machine learning algorithm used to group data into a predefined number of clusters, based on similarities between data points. It works by initially assigning \\(k\\) random centroids, then iteratively updating them by assigning each data point to the nearest centroid and recalculating the centroid’s position based on the mean of the points in each cluster. The process continues until the centroids stabilise, meaning they no longer change significantly. \\(k\\)-means is often used for tasks such as data segmentation, image compression, or anomaly detection. It is simple but may not work well with non-spherical or overlapping clusters.\n\n\n\nBecause all the data are stored in long format, with each London LSOA appearing on multiple rows for each category — such as separate rows for different age groups, ethnicities, countries of birth, and first or preferred languages - we need to transform it into a wide format. For example, instead of having multiple rows for an LSOA showing counts for different age groups all the information for each LSOA will be consolidated into a single row. Additionally, we will clean up the column names to follow standard R naming conventions and make the data easier to work with. We can automate this process using the janitor package.\nWe will begin with the age dataframe:\n\n\n\nR code\n\n# clean names\nlsoa_age &lt;- lsoa_age |&gt;\n    clean_names()\n\n# pivot\nlsoa_age &lt;- lsoa_age |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"age_5_categories\",\n        values_from = \"observation\")\n\n# clean names\nlsoa_age &lt;- lsoa_age |&gt;\n    clean_names()\n\n\n\n\n\n\n\n\nThe code above uses a pipe function: |&gt;. The pipe operator allows you to pass the output of one function directly into the next, streamlining your code. While it might be a bit confusing at first, you will find that it makes your code faster to write and easier to read. More importantly, it reduces the need to create multiple intermediate variables to store outputs.\n\n\n\nTo account for the non-uniformity of the areal units, we further need to convert the observations to percentages and only retain those columns that are likely to be meaningful in the context of the classification:\n\n\n\nR code\n\n# total observations\nlsoa_age &lt;- lsoa_age |&gt;\n    rowwise() |&gt;\n    mutate(age_pop = sum(across(2:6)))\n\n# total proportions, select columns\nlsoa_age &lt;- lsoa_age |&gt;\n    mutate(across(2:6, ~./age_pop)) |&gt;\n    select(1:6)\n\n# inspect\nhead(lsoa_age)\n\n\n# A tibble: 6 × 6\n# Rowwise: \n  lower_layer_super_output_areas_code aged_15_years_and_un…¹ aged_16_to_24_years\n  &lt;chr&gt;                                                &lt;dbl&gt;               &lt;dbl&gt;\n1 E01000001                                           0.0846              0.0744\n2 E01000002                                           0.0621              0.0889\n3 E01000003                                           0.0682              0.0706\n4 E01000005                                           0.127               0.178 \n5 E01000006                                           0.224               0.120 \n6 E01000007                                           0.257               0.103 \n# ℹ abbreviated name: ¹​aged_15_years_and_under\n# ℹ 3 more variables: aged_25_to_34_years &lt;dbl&gt;, aged_35_to_49_years &lt;dbl&gt;,\n#   aged_50_years_and_over &lt;dbl&gt;\n\n\nThis looks much better. We can do the same for the country of birth data:\n\n\n\nR code\n\n# prepare country of birth data\nlsoa_cob &lt;- lsoa_cob |&gt;\n    clean_names() |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"country_of_birth_8_categories\",\n        values_from = \"observation\") |&gt;\n    clean_names()\n\n# proportions, select columns\nlsoa_cob &lt;- lsoa_cob |&gt;\n    rowwise() |&gt;\n    mutate(cob_pop = sum(across(2:9))) |&gt;\n    mutate(across(2:9, ~./cob_pop)) |&gt;\n    select(-2, -10)\n\n\nAnd we can do the same for the ethnicity and language datasets:\n\n\n\nR code\n\n# prepare ethnicity data\nlsoa_eth &lt;- lsoa_eth |&gt;\n    clean_names() |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"ethnic_group_20_categories\",\n        values_from = \"observation\") |&gt;\n    clean_names()\n\n# proportions, select columns\nlsoa_eth &lt;- lsoa_eth |&gt;\n    rowwise() |&gt;\n    mutate(eth_pop = sum(across(2:21))) |&gt;\n    mutate(across(2:21, ~./eth_pop)) |&gt;\n    select(-2, -22)\n\n# prepare language data\nlsoa_lan &lt;- lsoa_lan |&gt;\n    clean_names() |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"main_language_11_categories\",\n        values_from = \"observation\") |&gt;\n    clean_names()\n\n# proportions, select columns\nlsoa_lan &lt;- lsoa_lan |&gt;\n    rowwise() |&gt;\n    mutate(lan_pop = sum(across(2:12))) |&gt;\n    mutate(across(2:12, ~./lan_pop)) |&gt;\n    select(-2, -11, -13)\n\n\nWe now have four separate datasets, each containing the proportions of usual residents classified into different groups based on age, country of birth, ethnicity, and language.\n\n\n\nWhere we initially selected variables from different demographic domains, not all variables may be suitable for inclusion. Firstly, the variables need to exhibit sufficient heterogeneity to ensure they capture meaningful differences between observations. Secondly, variables should not be highly correlated with one another, as this redundancy can skew the clustering results. Ensuring acceptable correlation between variables helps maintain the diversity of information and improves the robustness of the clustering outcome.\n\n\n\n\n\n\nVariable selection is often a time-consuming process that requires a combination of domain knowledge and more extensive exploratory analysis than is covered in this practical.\n\n\n\nA straightforward yet effective method to examine the distribution of our variables is to create boxplots for each variable. This can be efficiently achieved by using facet_wrap() to generate a matrix of panels, allowing us to visualise all variables in a single view.\n\n\n\n\n\n\nFor more details on facet_wrap(), you can refer to the ggplot2 documentation.\n\n\n\n\n\n\nR code\n\n# wide to long\nlsoa_age_wd &lt;- lsoa_age |&gt;\n    pivot_longer(cols = c(2:5), names_to = \"agegroup\", values_to = \"count\")\n\n# facet age\nggplot(lsoa_age_wd, aes(y = count)) + geom_boxplot() + facet_wrap(~agegroup, ncol = 2) +\n    theme_minimal() + ylab(\"\")\n\n\n\n\n\nFigure 1: Boxplots of the distribution of the age dataset.\n\n\n\n\nWhen repeating this process for the birth, ethnicity, and language variables, you will notice that some variables have a very limited distribution. Specifically, some variables may have a value of 0 for the majority of London LSOAs. As a rule of thumb, we will retain only those variables where at least 75% of the LSOAs have values different from 0.\n\n\n\n\n\n\nThis threshold of 75% is arbitrary, and in practice, more thorough consideration should be given when deciding whether to include or exclude a variable.\n\n\n\n\n\n\nR code\n\n# join\nlsoa_df &lt;- lsoa_age |&gt;\n    left_join(lsoa_cob, by = \"lower_layer_super_output_areas_code\") |&gt;\n    left_join(lsoa_eth, by = \"lower_layer_super_output_areas_code\") |&gt;\n    left_join(lsoa_lan, by = \"lower_layer_super_output_areas_code\")\n\n# calculate proportion of zeroes\nzero_prop &lt;- sapply(lsoa_df[2:41], function(x) {\n    mean(x == 0)\n})\n\n# extract variables with high proportion zeroes\nidx &lt;- which(zero_prop &gt; 0.25)\n\n# inspect\nidx\n\n\n   white_gypsy_or_irish_traveller            any_other_uk_languages \n                               27                                33 \n  oceanic_or_australian_languages north_or_south_american_languages \n                               37                                38 \n\n# remove variables with high proportion zeroes\nlsoa_df &lt;- lsoa_df |&gt;\n    select(-white_gypsy_or_irish_traveller, -any_other_uk_languages, -oceanic_or_australian_languages,\n        -north_or_south_american_languages)\n\n\n\n\n\n\n\nThe code above makes use of Boolean logic to calculate the proportion of zeroes within each variable. The x == 0 part checks each value in column x to see if it is equal to 0, returning TRUE or FALSE for each element. The mean() function is then used to calculate the average of the TRUE values in the column. Since TRUE is treated as 1 and FALSE as 0, this gives the proportion of values in the column that are equal to zero.\n\n\n\nWe can subsequently check for multicollinearity of the remaining variables. The easiest way to check the correlations between all variables is probably by visualising a correlation matrix:\n\n\n\nR code\n\n# inspect variable names\nnames(lsoa_df)\n\n\n [1] \"lower_layer_super_output_areas_code\"                                  \n [2] \"aged_15_years_and_under\"                                              \n [3] \"aged_16_to_24_years\"                                                  \n [4] \"aged_25_to_34_years\"                                                  \n [5] \"aged_35_to_49_years\"                                                  \n [6] \"aged_50_years_and_over\"                                               \n [7] \"europe_united_kingdom\"                                                \n [8] \"europe_ireland\"                                                       \n [9] \"europe_other_europe\"                                                  \n[10] \"africa\"                                                               \n[11] \"middle_east_and_asia\"                                                 \n[12] \"the_americas_and_the_caribbean\"                                       \n[13] \"antarctica_and_oceania_including_australasia_and_other\"               \n[14] \"asian_asian_british_or_asian_welsh_bangladeshi\"                       \n[15] \"asian_asian_british_or_asian_welsh_chinese\"                           \n[16] \"asian_asian_british_or_asian_welsh_indian\"                            \n[17] \"asian_asian_british_or_asian_welsh_pakistani\"                         \n[18] \"asian_asian_british_or_asian_welsh_other_asian\"                       \n[19] \"black_black_british_black_welsh_caribbean_or_african_african\"         \n[20] \"black_black_british_black_welsh_caribbean_or_african_caribbean\"       \n[21] \"black_black_british_black_welsh_caribbean_or_african_other_black\"     \n[22] \"mixed_or_multiple_ethnic_groups_white_and_asian\"                      \n[23] \"mixed_or_multiple_ethnic_groups_white_and_black_african\"              \n[24] \"mixed_or_multiple_ethnic_groups_white_and_black_caribbean\"            \n[25] \"mixed_or_multiple_ethnic_groups_other_mixed_or_multiple_ethnic_groups\"\n[26] \"white_english_welsh_scottish_northern_irish_or_british\"               \n[27] \"white_irish\"                                                          \n[28] \"white_roma\"                                                           \n[29] \"white_other_white\"                                                    \n[30] \"other_ethnic_group_arab\"                                              \n[31] \"other_ethnic_group_any_other_ethnic_group\"                            \n[32] \"english_or_welsh\"                                                     \n[33] \"european_languages_eu\"                                                \n[34] \"other_european_languages_non_eu\"                                      \n[35] \"asian_languages\"                                                      \n[36] \"african_languages\"                                                    \n[37] \"any_other_languages\"                                                  \n\n# change variable names to index to improve visualisation\nlsoa_df_vis &lt;- lsoa_df\nnames(lsoa_df_vis)[2:37] &lt;- paste0(\"v\", sprintf(\"%02d\", 1:36))\n\n# correlation matrix\ncor_mat &lt;- cor_pmat(lsoa_df_vis[, -1])\n\n# correlation plot\nggcorrplot(cor_mat, hc.order = FALSE, outline.col = \"#ffffff\", tl.cex = 8)\n\n\n\n\nFigure 2: Correlation plot of classification variables.\n\n\n\n\nFollowing the approach from Wyszomierski et al. (2024), we can define a weak correlation as lying between 0 and 0.40, moderate as between 0.41 and 0.65, strong as between 0.66 and 0.80, and very strong as between 0.81 and 1.\nA few strong and very strong correlations can be observed that probably should be removed; however, to maintain representation, here we decide to retain all variables.\n\n\n\nIf the input data are heavily skewed or contain outliers, \\(k\\)-means may produce less meaningful clusters. While normality is not required per se, it has been common to do this nonetheless. More important is to standardise the input variables, especially when they are measured on different scales. This ensures that each variable contributes equally to the clustering process.\n\n\n\nR code\n\n# inverse hyperbolic sine\nlsoa_df_vis[, -1] &lt;- sapply(lsoa_df_vis[-1], asinh)\n\n# range standardise\nlsoa_df_vis[, -1] &lt;- sapply(lsoa_df_vis[-1], function(x) {\n    (x - min(x))/(max(x) - min(x))\n})\n\n\n\n\n\nNow our data are prepared we will start by creating an elbow plot. The elbow method is a visual tool that helps determine the optimal number of clusters in a dataset. This is important because with \\(k\\)-means clustering you need to specify the numbers of clusters a priori. The elbow method involves running the clustering algorithm with varying numbers of clusters (\\(k\\)) and plotting the total explained variation (known as the Within Sum of Squares) against the number of clusters. The goal is to identify the ‘elbow’ point on the curve, where the rate of decrease in explained variation starts to slow. This point suggests that adding more clusters yields diminishing returns in terms of explained variation.\n\n\n\nR code\n\n# elbow plot\nfviz_nbclust(lsoa_df_vis[, -1], kmeans, nstart = 100, iter.max = 100, method = \"wss\")\n\n\n\n\n\nFigure 3: Elbow plot with ‘Within Sum of Squares’ against number of clusters.\n\n\n\n\nBased on the elbow plot, we can now choose the number of clusters and it looks like 6 clusters would be a reasonable choice.\n\n\n\n\n\n\nThe interpretation of an elbow plot can be quite subjective, and multiple options for the optimal number of clusters might be justified; for instance, 4, 5, or even 7 clusters could be reasonable choices. In addition to the elbow method, other techniques can aid in determining the optimal number of clusters, such as silhouette scores and the gap statistic. An alternative and helful approach is to use a clustergram, which is a two-dimensional plot that visualises the flows of observations between clusters as more clusters are added. This method illustrates how your data reshuffles with each additional cluster and provides insights into the quality of the splits. This method can be done in R, but currently easier to implement in Python.\n\n\n\n\n\n\nNow we have decided on the number of clusters, we can run our \\(k\\)-means analysis.\n\n\n\nR code\n\n# set seed for reproducibility\nset.seed(999)\n\n# k-means\nlsoa_clus &lt;- kmeans(lsoa_df_vis[, -1], centers = 6, nstart = 100, iter.max = 100)\n\n\nWe can inspect the object to get some information about our clusters:\n\n\n\nR code\n\n# inspect\nlsoa_clus\n\n\nK-means clustering with 6 clusters of sizes 796, 1097, 771, 1011, 851, 468\n\nCluster means:\n        v01       v02       v03       v04       v05       v06       v07\n1 0.4816225 0.1632210 0.2425566 0.4838983 0.4169123 0.5410477 0.1337158\n        v08       v09       v10        v11        v12        v13        v14\n1 0.3007540 0.2480613 0.2859754 0.08913663 0.05177222 0.14603013 0.06993627\n         v15        v16        v17        v18        v19        v20        v21\n1 0.12176548 0.10935022 0.20109979 0.18150482 0.11605092 0.12757934 0.09288236\n         v22        v23       v24       v25       v26        v27       v28\n1 0.07473711 0.14662903 0.1842217 0.3522638 0.1490577 0.02997040 0.2423784\n         v29       v30       v31       v32        v33        v34        v35\n1 0.07148504 0.2193009 0.5870244 0.2411272 0.07541661 0.23467242 0.10174187\n         v36\n1 0.10216507\n [ reached getOption(\"max.print\") -- omitted 5 rows ]\n\nClustering vector:\n [1] 4 4 4 1 1 5 5 6 6 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 2 2 1 1 2 2 2 1 1 1\n[39] 1 1 1 1 5 1 5 1 1 1 1 1\n [ reached getOption(\"max.print\") -- omitted 4944 entries ]\n\nWithin cluster sum of squares by cluster:\n[1] 259.0272 177.7951 288.8625 232.7770 298.9145 160.1702\n (between_SS / total_SS =  48.5 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\n\n\nWe now need to perform some post-processing to extract useful summary data for each cluster. To characterise the clusters, we can compare the global mean values of each variable with the mean values specific to each cluster.\n\n\n\nR code\n\n# global means\nglob_means &lt;- colMeans(lsoa_df_vis[, -1])\n\n# add clusters to input data\nlsoa_df_vis &lt;- cbind(lsoa_df_vis, cluster = lsoa_clus$cluster)\n\n# cluster means\ncluster_means &lt;- lsoa_df_vis |&gt;\n    group_by(cluster) |&gt;\n    summarise(across(2:37, mean))\n\n# difference\ncluster_diffs &lt;- cluster_means |&gt;\n    mutate(across(2:37, ~. - glob_means[cur_column()]))\n\n\nThese comparisons can then be visualised using, for instance, a radial bar plot:\n\n\n\nR code\n\n# to long format\ncluster_diffs_long &lt;- cluster_diffs |&gt;\n    pivot_longer(!cluster, names_to = \"vars\", values_to = \"score\")\n\n# facet clusters\nggplot(cluster_diffs_long, aes(x = factor(vars), y = score)) + geom_bar(stat = \"identity\") +\n    coord_radial(rotate.angle = TRUE, expand = FALSE) + facet_wrap(~cluster, ncol = 3) +\n    theme_minimal() + xlab(\"\") + ylab(\"\")\n\n\n\n\n\nFigure 4: Radial barplots of cluster means for each input variable.\n\n\n\n\nThese plots can serve as a foundation for creating pen portraits by closely examining which variables drive each cluster.\n\n\n\n\n\n\nFor easier interpretation, these values can be transformed into index scores, allowing us to assess which variables are under- or overrepresented within each cluster group.\n\n\n\nOf course, we can also map the results:\n\n\n\nR code\n\n# read spatial dataset\nlsoa21 &lt;- st_read(\"data/London-LSOA-2021.gpkg\")\n\n\nReading layer `LSOA2021_London' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0114/data/London-LSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 4994 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# join\nlsoa21 &lt;- cbind(lsoa21, cluster = lsoa_clus$cluster)\n\n# shape, polygon\ntm_shape(lsoa21) +\n\n  # specify column, colours\n  tm_polygons(\n    col = \"cluster\",\n    palette = c(\"#feebe2\", \"#fbb4b9\", \"#f768a1\", \"#c51b8a\", \"#7a0177\"),\n    border.col = \"#ffffff\",\n    border.alpha = 0.1,\n    title = \"Cluster number\"\n  ) +\n\n  # set layout\n  tm_layout(\n    legend.outside = FALSE,\n    legend.position = c(\"right\", \"bottom\"),\n    frame = FALSE\n  )\n\n\n\n\nFigure 5: Classification of London LSOAs based on several demographic variables."
  },
  {
    "objectID": "01-geodemographics.html#assignment",
    "href": "01-geodemographics.html#assignment",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "The creation of a geodemographic classification is an iterative process. This typically includes adding or removing variables, adjusting the number of clusters, and grouping data in different ways to achieve the most meaningful segmentation. Try to do the following:\n\nDownload the two datasets provided below and save them to your data folder. The datasets include:\n\nA csv file containing the number of people aged 16 years and older by occupational category, as defined by the Standard Occupational Classification 2020, aggregated by 2021 LSOAs.\nA csv file containing the number of people aged 16 years and older by their highest level of qualification, also aggregated to the LSOA level.\n\nPrepare these two datasets and retain only those variables that are potentially meaningful. Filter out any variables with a high proportion of zero values.\nMerge the education and occupation dataset with the dataset used to generate the initial geodemographic classification. Check for multicollinearity and consider removing any variables that are highly correlated.\nPerform \\(k\\)-means clustering on your extended dataset. Make sure to select an appropriate number of clusters for your analysis.\nInterpret the individual clusters in terms of the variables that are under- or overrepresented.\n\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon LSOA Census 2021 Occupation\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Education\ncsv\nDownload"
  },
  {
    "objectID": "01-geodemographics.html#before-you-leave",
    "href": "01-geodemographics.html#before-you-leave",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "Having finished this tutorial, you should now understand the basics of a geodemographic classification. That is all for this week!"
  },
  {
    "objectID": "02-network.html",
    "href": "02-network.html",
    "title": "Accessibility Analysis",
    "section": "",
    "text": "Accessibility is often described as the ease with which individuals can reach places and opportunities, such as employment, public services, and cultural activities. We can utilise transport network data to quantify accessibility and characterise areas based on their accessibility levels. This week, we will use the dodgr R library to measure accessibility between different points of interest by calculating network distances between them.\n\n\nYou can download the slides of this week’s lecture here: [Link].\n\n\n\n\n\n\nGeurs, K., Van Wee, B. 2004. Accessibility evaluation of land-use and transport strategies: review and research directions. Journal of Transport Geography 12(2): 127-140. [Link]\nHiggins, C., Palm, M. DeJohn, A. et al. 2022. Calculating place-based transit accessibility: Methods, tools and algorithmic dependence. Journal of Transport and Land Use 15(1): 95-116. [Link]\n\n\n\n\n\nVan Dijk, J., Krygsman, S. and De Jong, T. 2015. Toward spatial justice: The spatial equity effects of a toll road in Cape Town, South Africa. Journal of Transport and Land Use 8(3): 95-114. [Link]\nVan Dijk, J. and De Jong, T. 2017. Post-processing GPS-tracks in reconstructing travelled routes in a GIS-environment: network subset selection and attribute adjustment. Annals of GIS 23(3): 203-217. [Link]\n\n\n\n\n\nThis week, we will analyse the accessibility of fast-food outlets in the London Borough of Lambeth. Specifically, we will examine how closely these outlets are situated near primary and secondary schools and investigate any potential relationships between their proximity and the relative levels of deprivation in the area.\nWe will extract the points of interest that we will use for this analysis from the Point of Interest (POI) data for the United Kingdom, obtained from the Overture Maps Foundation and pre-processed by the Consumer Data Research Centre to provide users with easy access.\nYou can download a subset of the POI dataset via the link provided below. A copy of the 2021 London LSOAs spatial boundaries, the boundaries of the London Boroughs, and the 2019 English Index of Multiple Deprivation. Save these files in your project folder under data.\n\n\n\nFile\nType\nLink\n\n\n\n\nLambeth Overture Points of Interest 2024\nGeoPackage\nDownload\n\n\nLondon LSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\nLondon Borough Spatial Boundaries\nGeoPackage\nDownload\n\n\nEngland 2019 Index of Multiple Deprivation\ncsv\nDownload\n\n\n\n\n\n\n\n\n\nTo extract the Lambeth Overture Points of Interest data, a 2-kilometre buffer was applied around the boundaries of Lambeth. This approach ensures that points just outside the study area are included, as locations beyond the borough boundary may still be accessible to residents and could represent the nearest available options.\n\n\n\nOpen a new script and save this as w07-accessibility.r. We will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\nlibrary(osmdata)\nlibrary(dodgr)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nNext, we can load the spatial data into R.\n\n\n\nR code\n\n# read poi data\npoi24 &lt;- st_read(\"data/Lambeth-POI-2024.gpkg\")\n\n\nReading layer `Lambeth-POI-2024' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0114/data/Lambeth-POI-2024.gpkg' \n  using driver `GPKG'\nSimple feature collection with 65060 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526556.6 ymin: 167827 xmax: 535640.4 ymax: 182673.8\nProjected CRS: OSGB36 / British National Grid\n\n# read lsoa dataset\nlsoa21 &lt;- st_read(\"data/London-LSOA-2021.gpkg\")\n\nReading layer `LSOA2021_London' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0114/data/London-LSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 4994 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# read borough dataset\nborough &lt;- st_read(\"data/London-Boroughs.gpkg\")\n\nReading layer `london_boroughs' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0114/data/London-Boroughs.gpkg' \n  using driver `GPKG'\nSimple feature collection with 33 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9\nProjected CRS: OSGB36 / British National Grid\n\n\nNow, carefully examine each individual dataframe to understand how the data is structured and what information it contains.\n\n\n\nR code\n\n# inspect poi data\nhead(poi24)\n\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526913.4 ymin: 169695.2 xmax: 526945.5 ymax: 169970.8\nProjected CRS: OSGB36 / British National Grid\n                                id    primary_name       main_category\n1 08f194ada9716b86030eab41bbd4207e \"Gorgeous Grub\" \"burger_restaurant\"\n2 08f194ada9715a1903d73f4aef170602    \"TLC Direct\"   \"wholesale_store\"\n3 08f194ada944cba203fa613de4f5e6d5     \"JD Sports\"       \"sports_wear\"\n4 08f194ada9449a8a0345a466a0a6ece9       \"Lidl GB\"       \"supermarket\"\n                    alternate_category                                 address\n1   eat_and_drink|fast_food_restaurant                 \"1 Prince Georges Road\"\n2 professional_services|lighting_store                      \"280 Western Road\"\n3            sporting_goods|shoe_store \"Unit 2 Tandem Centre Top Of Church Rd\"\n4          retail|fast_food_restaurant                         \"Colliers Wood\"\n         locality   postcode region country source   source_record_id\n1        \"London\"   \"SW19 2\"  \"ENG\"    \"GB\" \"meta\"  \"232538816864698\"\n2        \"London\" \"SW19 2QA\"  \"ENG\"    \"GB\" \"meta\" \"1959707454355017\"\n3 \"Colliers Wood\" \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\"  \"644899945690935\"\n4        \"London\" \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\"  \"111430837210163\"\n                            geom\n1 MULTIPOINT ((526913.4 16984...\n2 MULTIPOINT ((526921.1 16969...\n3 MULTIPOINT ((526915.7 16997...\n4 MULTIPOINT ((526922.2 16988...\n [ reached 'max' / getOption(\"max.print\") -- omitted 2 rows ]\n\n# inspect country of birth data\nhead(lsoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 531948.3 ymin: 180733.9 xmax: 545296.2 ymax: 184700.6\nProjected CRS: OSGB36 / British National Grid\n   LSOA21CD                  LSOA21NM  BNG_E  BNG_N      LONG      LAT\n1 E01000001       City of London 001A 532123 181632 -0.097140 51.51816\n2 E01000002       City of London 001B 532480 181715 -0.091970 51.51882\n3 E01000003       City of London 001C 532239 182033 -0.095320 51.52174\n4 E01000005       City of London 001E 533581 181283 -0.076270 51.51468\n5 E01000006 Barking and Dagenham 016A 544994 184274  0.089317 51.53875\n                                GlobalID pop2021                           geom\n1 {1A259A13-A525-4858-9CB0-E4952BA01AF6}    1473 MULTIPOLYGON (((532105.3 18...\n2 {1233E433-0B0D-4807-8117-17A83C23960D}    1384 MULTIPOLYGON (((532634.5 18...\n3 {5163B7CB-4FFE-4F41-95B9-AA6CFC0508A3}    1613 MULTIPOLYGON (((532135.1 18...\n4 {2AF8015E-386E-456D-A45A-D0A223C340DF}    1101 MULTIPOLYGON (((533808 1807...\n5 {B492B45E-175E-4E77-B0B5-5B2FD6993EF4}    1842 MULTIPOLYGON (((545122 1843...\n [ reached 'max' / getOption(\"max.print\") -- omitted 1 rows ]\n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\n\n\nThe inspection shows that the POI dataset contains a wide variety of location types, with each point tagged under a main and alternative category, as provided by the Overture Maps Foundation via Meta and Microsoft. However, these tags may not be consistent across the dataset, so we will need to identify specific keywords to filter the main_category and alternate_category columns. We will start by filtering out all POIs where the word school features in the main_category column:\n\n\n\nR code\n\n# filter school poi data\npoi_schools &lt;- poi24 |&gt;\n    filter(str_detect(main_category, \"school\"))\n\n# inspect\nhead(unique(poi_schools$main_category), n = 50)\n\n\n [1] \"\\\"day_care_preschool\\\"\"              \"\\\"driving_school\\\"\"                 \n [3] \"\\\"elementary_school\\\"\"               \"\\\"school\\\"\"                         \n [5] \"\\\"language_school\\\"\"                 \"\\\"music_school\\\"\"                   \n [7] \"\\\"specialty_school\\\"\"                \"\\\"preschool\\\"\"                      \n [9] \"\\\"dance_school\\\"\"                    \"\\\"high_school\\\"\"                    \n[11] \"\\\"drama_school\\\"\"                    \"\\\"cooking_school\\\"\"                 \n[13] \"\\\"middle_school\\\"\"                   \"\\\"vocational_and_technical_school\\\"\"\n[15] \"\\\"art_school\\\"\"                      \"\\\"private_school\\\"\"                 \n[17] \"\\\"religious_school\\\"\"                \"\\\"nursing_school\\\"\"                 \n[19] \"\\\"montessori_school\\\"\"               \"\\\"public_school\\\"\"                  \n[21] \"\\\"cosmetology_school\\\"\"              \"\\\"medical_school\\\"\"                 \n[23] \"\\\"engineering_schools\\\"\"             \"\\\"massage_school\\\"\"                 \n[25] \"\\\"business_schools\\\"\"                \"\\\"law_schools\\\"\"                    \n[27] \"\\\"medical_sciences_schools\\\"\"        \"\\\"sports_school\\\"\"                  \n[29] \"\\\"flight_school\\\"\"                  \n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\nThis is still a very large list, and not all POIs containing the string school should be included. However, this initial selection gives us a more manageable list from which we can choose the relevant tags. Once we have made our selections, we can further filter the dataset accordingly as well as clip the dataset to the administrative boundaries of Lambeth.\n\n\n\nR code\n\n# remove quotes for easier processing\npoi_schools &lt;- poi_schools |&gt;\n    mutate(main_category = str_replace_all(main_category, \"\\\"\", \"\"))\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(main_category == \"elementary_school\" | main_category == \"high_school\" |\n        main_category == \"middle_school\" | main_category == \"private_school\" | main_category ==\n        \"public_school\" | main_category == \"school\")\n\n# filter school poi data\nlambeth &lt;- borough |&gt;\n    filter(name == \"Lambeth\")\n\npoi_schools &lt;- poi_schools |&gt;\n    st_intersection(lambeth) |&gt;\n    select(1:11)\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n# inspect\npoi_schools\n\nSimple feature collection with 141 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 169846.4 xmax: 533065.9 ymax: 180398\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                 id\n6  08f194ad1a394235035f3ab7c2e4721d\n7  08f194ad1a8da734035945d69c357ddd\n8  08f194ad1abb648603defd9d76b4c314\n27 08f194ad130f0cd303c1c9f9b42438f8\n                                               primary_name     main_category\n6                         \"Woodmansterne Children's Centre\" elementary_school\n7   \"Immanuel & St Andrew Church of England Primary School\"            school\n8  \"Monkey Puzzle Day Nursery & Preschool Streatham Common\"            school\n27                                     \"Campsbourne School\"            school\n                        alternate_category                   address locality\n6                         school|education            \"Stockport Rd\"     &lt;NA&gt;\n7              elementary_school|education           \"Northanger Rd\"     &lt;NA&gt;\n8  education|public_service_and_government \"496 Streatham High Road\" \"London\"\n27                               education                      &lt;NA&gt; \"London\"\n     postcode region country source   source_record_id\n6  \"SW16 5XE\"   &lt;NA&gt;    \"GB\" \"meta\"  \"114577088601307\"\n7  \"SW16 5SL\"   &lt;NA&gt;    \"GB\" \"meta\"  \"128479257200832\"\n8  \"SW16 3QB\"  \"ENG\"    \"GB\" \"meta\" \"1092187950854118\"\n27       &lt;NA&gt;   &lt;NA&gt;    \"GB\" \"meta\"  \"114411542481619\"\n                        geom\n6  POINT (529701.5 169846.4)\n7  POINT (530016.4 170574.1)\n8  POINT (530208.6 170587.9)\n27 POINT (528819.8 174228.7)\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nThis is still a rather long list and likely inaccurate. According to Lambeth Council Education Statistics, there should be 80 primary and secondary schools across the borough. We can use the alternate_category column to further narrow down our results.\n\n\n\n\n\n\nYou can inspect the different tags and their frequencies easily by creating a frequency table: table(poi_schools$alternate_category).\n\n\n\n\n\n\nR code\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(str_detect(alternate_category, \"elementary_school\") | str_detect(alternate_category,\n        \"high_school\") | str_detect(alternate_category, \"middle_school\") | str_detect(alternate_category,\n        \"private_school\") | str_detect(alternate_category, \"public_school\"))\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 58 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 170025.3 xmax: 532897.2 ymax: 179678.2\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                id\n1 08f194ad1a8da734035945d69c357ddd\n2 08f194ad1a70460d037da737c256001b\n3 08f194ad1c2dc81c032e9e0aa296a8d1\n4 08f194ad1e4cec5903fafb7496a2d2f3\n                                             primary_name     main_category\n1 \"Immanuel & St Andrew Church of England Primary School\"            school\n2                                \"Granton Primary School\" elementary_school\n3                 \"Kingswood Primary School (Upper Site)\" elementary_school\n4                              \"Battersea Grammar School\"            school\n           alternate_category          address locality   postcode region\n1 elementary_school|education  \"Northanger Rd\"     &lt;NA&gt; \"SW16 5SL\"   &lt;NA&gt;\n2        school|public_school     \"Granton Rd\"     &lt;NA&gt; \"SW16 5AN\"   &lt;NA&gt;\n3          school|high_school \"193 Gipsy Road\" \"London\"   \"SE27 9\"  \"ENG\"\n4       high_school|education             &lt;NA&gt; \"London\"       &lt;NA&gt;   &lt;NA&gt;\n  country source  source_record_id                      geom\n1    \"GB\" \"meta\" \"128479257200832\" POINT (530016.4 170574.1)\n2    \"GB\" \"meta\" \"235737420093504\" POINT (529299.7 170025.3)\n3    \"GB\" \"meta\" \"110066125723254\" POINT (532897.2 171498.4)\n4    \"GB\" \"meta\" \"103107239728950\" POINT (529523.9 172310.9)\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nSince the POI dataset is compiled from various open sources, the data quality is not guaranteed. Some schools may be missing, while others could be duplicated, perhaps under slightly different names or because different buildings have been assigned separate point locations. However, it is unlikely that more than one school would share the same postcode. Therefore, we will use postcode information (where available) to finalise our school selection and remove any likely duplicates.\n\n\n\nR code\n\n# identify duplicate postcodes\npoi_schools &lt;- poi_schools |&gt;\n    group_by(postcode) |&gt;\n    mutate(rank = rank(primary_name)) |&gt;\n    ungroup()\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(is.na(postcode) | rank == 1) |&gt;\n    select(-rank)\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 54 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 170025.3 xmax: 532897.2 ymax: 179678.2\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 54 × 12\n   id    primary_name main_category alternate_category address locality postcode\n   &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;              &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n 1 08f1… \"\\\"Immanuel… school        elementary_school… \"\\\"Nor…  &lt;NA&gt;    \"\\\"SW16…\n 2 08f1… \"\\\"Granton … elementary_s… school|public_sch… \"\\\"Gra…  &lt;NA&gt;    \"\\\"SW16…\n 3 08f1… \"\\\"Kingswoo… elementary_s… school|high_school \"\\\"193… \"\\\"Lond… \"\\\"SE27…\n 4 08f1… \"\\\"Batterse… school        high_school|educa…  &lt;NA&gt;   \"\\\"Lond…  &lt;NA&gt;   \n 5 08f1… \"\\\"St Bede'… school        elementary_school… \"\\\"St …  &lt;NA&gt;    \"\\\"SW12…\n 6 08f1… \"\\\"St Leona… school        elementary_school… \"\\\"42 … \"\\\"Lond… \"\\\"SW16…\n 7 08f1… \"\\\"Richard … elementary_s… college_universit… \"\\\"New…  &lt;NA&gt;    \"\\\"SW2 …\n 8 08f1… \"\\\"Henry Ca… school        high_school|eleme… \"\\\"Hyd…  &lt;NA&gt;    \"\\\"SW12…\n 9 08f1… \"\\\"South Ba… school        high_school|b2b_s… \"\\\"56 … \"\\\"Lond… \"\\\"SW2 …\n10 08f1… \"\\\"Glenbroo… elementary_s… school|public_sch… \"\\\"Cla…  &lt;NA&gt;    \"\\\"SW4 …\n# ℹ 44 more rows\n# ℹ 5 more variables: region &lt;chr&gt;, country &lt;chr&gt;, source &lt;chr&gt;,\n#   source_record_id &lt;chr&gt;, geom &lt;POINT [m]&gt;\n\n\nAlthough we now have fewer schools than we had expected, either due to overly restrictive filtering of tags or because some school locations are not recorded in the dataset, we will proceed with the current data.\n\n\n\n\n\n\nVariable preparation can be a time-consuming process that often necessitates a more extensive exploratory analysis to ensure sufficient data quality. This may involve sourcing additional data to supplement your existing dataset.\n\n\n\nWe can now use a similar approach to approximate the locations of fast food outlets in the Borough.\n\n\n\nR code\n\n# filter fast food poi data\npoi_fastfood &lt;- poi24 |&gt;\n    filter(str_detect(main_category, \"fast_food_restaurant\") | str_detect(alternate_category,\n        \"fast_food_restaurant\") | str_detect(alternate_category, \"chicken_restaurant\") |\n        str_detect(alternate_category, \"burger_restaurant\"))\n\n# inspect\npoi_fastfood\n\n\nSimple feature collection with 1444 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526666.3 ymin: 168272.9 xmax: 535546.9 ymax: 182554\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                id     primary_name          main_category\n1 08f194ada9716b86030eab41bbd4207e  \"Gorgeous Grub\"    \"burger_restaurant\"\n2 08f194ada9449a8a0345a466a0a6ece9        \"Lidl GB\"          \"supermarket\"\n3 08f194ada944daa80328c6604dab3503     \"Moss Bros.\" \"men's_clothing_store\"\n4 08f194ada932ad8603db11bbb7f953a7 \"Livi's Cuisine\"   \"african_restaurant\"\n                  alternate_category                          address  locality\n1 eat_and_drink|fast_food_restaurant          \"1 Prince Georges Road\"  \"London\"\n2        retail|fast_food_restaurant                  \"Colliers Wood\"  \"London\"\n3               fast_food_restaurant \"Unit 5, Tandem Shopping Centre\"  \"London\"\n4       caterer|fast_food_restaurant                   \"1 Locks Lane\" \"Mitcham\"\n    postcode region country source  source_record_id\n1   \"SW19 2\"  \"ENG\"    \"GB\" \"meta\" \"232538816864698\"\n2 \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\" \"111430837210163\"\n3 \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\" \"478090646011341\"\n4    \"CR4 2\"  \"ENG\"    \"GB\" \"meta\" \"231745500530140\"\n                            geom\n1 MULTIPOINT ((526913.4 16984...\n2 MULTIPOINT ((526922.2 16988...\n3 MULTIPOINT ((526945.5 16992...\n4 MULTIPOINT ((527970.3 16955...\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nLet’s map both dataset to get an idea of how the data look like:\n\n\n\nR code\n\n# combine for mapping\npoi_schools &lt;- poi_schools |&gt;\n  mutate(type = \"School\")\npoi_fastfood &lt;- poi_fastfood |&gt;\n  mutate(type = \"Fast food\")\npoi_lambeth &lt;- rbind(poi_schools, poi_fastfood)\n\n# shape, polygon\ntm_shape(lambeth) +\n\n  # specify column, classes\n  tm_polygons(\n    col = \"#f0f0f0\",\n  ) +\n\n  # shape, points\n  tm_shape(poi_lambeth) +\n\n  # specify column, colours\n  tm_dots(\n    col = \"type\",\n    size = 0.05,\n    palette = c(\"#beaed4\", \"#fdc086\"),\n    title = \"POI type\"\n  ) +\n\n  # set layout\n  tm_layout(\n    legend.outside = TRUE,\n    legend.position = c(\"right\", \"bottom\"),\n    frame = FALSE\n  )\n\n\n\n\n\nFigure 1: Extracted school and fast food locations for Lambeth.\n\n\n\n\n\n\n\nIn addition to the locations of interest, we need network data to assess the accessibility of schools in relation to fast food outlets. We will use OpenStreetMap to extract road segment data. Similar to the POI dataset, OSM uses key and value tags to categorise the features within its dataset.\n\n\n\n\n\n\nOpenStreetMap (OSM) is a free, editable map of the world, but its coverage is uneven globally. However, the accuracy and quality of the data can at times be questionable, with details such as road types and speed limits missing. The OpenStreetMap Wiki provides more details on the tagging system.\n\n\n\nTo download the Lambeth road network dataset, we first need to define our bounding box coordinates. We will then use these coordinates in our OSM query to extract specific types of road segments within the defined search area. Our focus will be on selecting all OSM features with the highway tag that are likely to be used by pedestrians (e.g. excluding motorways).\n\n\n\nR code\n\n# define our bbox coordinates, use WGS84\nbbox_lambeth &lt;- poi24 |&gt;\n    st_transform(4326) |&gt;\n    st_bbox()\n\n# osm query\nosm_network &lt;- opq(bbox = bbox_lambeth) |&gt;\n    add_osm_feature(key = \"highway\", value = c(\"primary\", \"secondary\", \"tertiary\",\n        \"residential\", \"path\", \"footway\", \"unclassified\", \"living_street\", \"pedestrian\")) |&gt;\n    osmdata_sf()\n\n\n\n\n\n\n\n\nIn some cases, the OSM query may return an error, particularly when multiple users from the same location are executing the exact same query. If so, you can download a prepared copy of the data here: [Download].\nYou can load this copy into R through load('data/London-OSM-Roads.RData')\n\n\n\nThe returned osm_network object contains a variety of elements with the specified tags. Our next step is to extract the spatial data from this object to create our road network dataset. Specifically, we will extract the edges of the network, which represent the lines of the roads, as well as the nodes, which represent the points where the roads start, end, or intersect.\n\n\n\nR code\n\n# extract the nodes, with their osm_id.\nosm_network_nodes &lt;- osm_network$osm_points[, \"osm_id\"]\n\n# extract the edges\nosm_network_edges &lt;- osm_network$osm_lines[, c(\"osm_id\", \"name\", \"highway\", \"maxspeed\",\n    \"oneway\")]\n\n# inspect\nhead(osm_network_nodes)\n\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -0.1541499 ymin: 51.52434 xmax: -0.1457924 ymax: 51.52698\nGeodetic CRS:  WGS 84\n      osm_id                    geometry\n78112  78112 POINT (-0.1457924 51.52698)\n99878  99878 POINT (-0.1529787 51.52434)\n99879  99879 POINT (-0.1532934 51.52482)\n99880  99880 POINT (-0.1535802 51.52508)\n99882  99882 POINT (-0.1541499 51.52567)\n99883  99883 POINT (-0.1541362 51.52598)\n\n# inspect\nhead(osm_network_edges)\n\nSimple feature collection with 6 features and 5 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -0.1398347 ymin: 51.50608 xmax: -0.0821093 ymax: 51.5246\nGeodetic CRS:  WGS 84\n         osm_id                 name     highway maxspeed oneway\n31030     31030          Grafton Way     primary   20 mph    yes\n31039     31039 Tottenham Court Road     primary   20 mph   &lt;NA&gt;\n31959     31959     Cleveland Street residential   20 mph    yes\n554369   554369  King William Street    tertiary   20 mph    yes\n554526   554526     Fenchurch Street    tertiary   20 mph   &lt;NA&gt;\n1530592 1530592  Borough High Street     primary   30 mph    yes\n                              geometry\n31030   LINESTRING (-0.1349153 51.5...\n31039   LINESTRING (-0.1303693 51.5...\n31959   LINESTRING (-0.139512 51.52...\n554369  LINESTRING (-0.08745 51.511...\n554526  LINESTRING (-0.085135 51.51...\n1530592 LINESTRING (-0.0882957 51.5...\n\n\nWe can quickly map the edges to see how the road network looks like:\n\n\n\nR code\n\n# shape, polygon\ntm_shape(osm_network_edges) +\n\n  # specify column, classes\n  tm_lines(\n    col = \"#bdbdbd\",\n    lwd = 0.2,\n  ) +\n\n  # shape, polygon\n  tm_shape(lambeth) +\n\n  # specify column, classes\n  tm_borders(\n    col = \"#252525\",\n    lwd = 2\n  ) +\n\n  # set legend\n  tm_add_legend(\n    type = \"line\",\n    labels = \"Road segments\",\n    col = \"#bdbdbd\"\n  ) +\n\n  tm_add_legend(\n    type = \"line\",\n    labels = \"Outline Lambeth\",\n    col = \"#252525\"\n  ) +\n\n  # set layout\n  tm_layout(\n    frame = FALSE,\n    legend.outside = TRUE,\n    legend.position = c(\"right\", \"bottom\"),\n  )\n\n\n\n\n\nFigure 2: Extracted road network data for Lambeth."
  },
  {
    "objectID": "02-network.html#lecture-w08",
    "href": "02-network.html#lecture-w08",
    "title": "Accessibility Analysis",
    "section": "",
    "text": "You can download the slides of this week’s lecture here: [Link]."
  },
  {
    "objectID": "02-network.html#reading-w08",
    "href": "02-network.html#reading-w08",
    "title": "Accessibility Analysis",
    "section": "",
    "text": "Geurs, K., Van Wee, B. 2004. Accessibility evaluation of land-use and transport strategies: review and research directions. Journal of Transport Geography 12(2): 127-140. [Link]\nHiggins, C., Palm, M. DeJohn, A. et al. 2022. Calculating place-based transit accessibility: Methods, tools and algorithmic dependence. Journal of Transport and Land Use 15(1): 95-116. [Link]\n\n\n\n\n\nVan Dijk, J., Krygsman, S. and De Jong, T. 2015. Toward spatial justice: The spatial equity effects of a toll road in Cape Town, South Africa. Journal of Transport and Land Use 8(3): 95-114. [Link]\nVan Dijk, J. and De Jong, T. 2017. Post-processing GPS-tracks in reconstructing travelled routes in a GIS-environment: network subset selection and attribute adjustment. Annals of GIS 23(3): 203-217. [Link]"
  },
  {
    "objectID": "02-network.html#accessibility-in-lambeth",
    "href": "02-network.html#accessibility-in-lambeth",
    "title": "Accessibility Analysis",
    "section": "",
    "text": "This week, we will analyse the accessibility of fast-food outlets in the London Borough of Lambeth. Specifically, we will examine how closely these outlets are situated near primary and secondary schools and investigate any potential relationships between their proximity and the relative levels of deprivation in the area.\nWe will extract the points of interest that we will use for this analysis from the Point of Interest (POI) data for the United Kingdom, obtained from the Overture Maps Foundation and pre-processed by the Consumer Data Research Centre to provide users with easy access.\nYou can download a subset of the POI dataset via the link provided below. A copy of the 2021 London LSOAs spatial boundaries, the boundaries of the London Boroughs, and the 2019 English Index of Multiple Deprivation. Save these files in your project folder under data.\n\n\n\nFile\nType\nLink\n\n\n\n\nLambeth Overture Points of Interest 2024\nGeoPackage\nDownload\n\n\nLondon LSOA 2021 Spatial Boundaries\nGeoPackage\nDownload\n\n\nLondon Borough Spatial Boundaries\nGeoPackage\nDownload\n\n\nEngland 2019 Index of Multiple Deprivation\ncsv\nDownload\n\n\n\n\n\n\n\n\n\nTo extract the Lambeth Overture Points of Interest data, a 2-kilometre buffer was applied around the boundaries of Lambeth. This approach ensures that points just outside the study area are included, as locations beyond the borough boundary may still be accessible to residents and could represent the nearest available options.\n\n\n\nOpen a new script and save this as w07-accessibility.r. We will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\nlibrary(osmdata)\nlibrary(dodgr)\n\n\n\n\n\n\n\n\nYou may have to install some of these libraries if you have not used these before.\n\n\n\nNext, we can load the spatial data into R.\n\n\n\nR code\n\n# read poi data\npoi24 &lt;- st_read(\"data/Lambeth-POI-2024.gpkg\")\n\n\nReading layer `Lambeth-POI-2024' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0114/data/Lambeth-POI-2024.gpkg' \n  using driver `GPKG'\nSimple feature collection with 65060 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526556.6 ymin: 167827 xmax: 535640.4 ymax: 182673.8\nProjected CRS: OSGB36 / British National Grid\n\n# read lsoa dataset\nlsoa21 &lt;- st_read(\"data/London-LSOA-2021.gpkg\")\n\nReading layer `LSOA2021_London' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0114/data/London-LSOA-2021.gpkg' \n  using driver `GPKG'\nSimple feature collection with 4994 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6\nProjected CRS: OSGB36 / British National Grid\n\n# read borough dataset\nborough &lt;- st_read(\"data/London-Boroughs.gpkg\")\n\nReading layer `london_boroughs' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/GEOG0114/data/London-Boroughs.gpkg' \n  using driver `GPKG'\nSimple feature collection with 33 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9\nProjected CRS: OSGB36 / British National Grid\n\n\nNow, carefully examine each individual dataframe to understand how the data is structured and what information it contains.\n\n\n\nR code\n\n# inspect poi data\nhead(poi24)\n\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526913.4 ymin: 169695.2 xmax: 526945.5 ymax: 169970.8\nProjected CRS: OSGB36 / British National Grid\n                                id    primary_name       main_category\n1 08f194ada9716b86030eab41bbd4207e \"Gorgeous Grub\" \"burger_restaurant\"\n2 08f194ada9715a1903d73f4aef170602    \"TLC Direct\"   \"wholesale_store\"\n3 08f194ada944cba203fa613de4f5e6d5     \"JD Sports\"       \"sports_wear\"\n4 08f194ada9449a8a0345a466a0a6ece9       \"Lidl GB\"       \"supermarket\"\n                    alternate_category                                 address\n1   eat_and_drink|fast_food_restaurant                 \"1 Prince Georges Road\"\n2 professional_services|lighting_store                      \"280 Western Road\"\n3            sporting_goods|shoe_store \"Unit 2 Tandem Centre Top Of Church Rd\"\n4          retail|fast_food_restaurant                         \"Colliers Wood\"\n         locality   postcode region country source   source_record_id\n1        \"London\"   \"SW19 2\"  \"ENG\"    \"GB\" \"meta\"  \"232538816864698\"\n2        \"London\" \"SW19 2QA\"  \"ENG\"    \"GB\" \"meta\" \"1959707454355017\"\n3 \"Colliers Wood\" \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\"  \"644899945690935\"\n4        \"London\" \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\"  \"111430837210163\"\n                            geom\n1 MULTIPOINT ((526913.4 16984...\n2 MULTIPOINT ((526921.1 16969...\n3 MULTIPOINT ((526915.7 16997...\n4 MULTIPOINT ((526922.2 16988...\n [ reached 'max' / getOption(\"max.print\") -- omitted 2 rows ]\n\n# inspect country of birth data\nhead(lsoa21)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 531948.3 ymin: 180733.9 xmax: 545296.2 ymax: 184700.6\nProjected CRS: OSGB36 / British National Grid\n   LSOA21CD                  LSOA21NM  BNG_E  BNG_N      LONG      LAT\n1 E01000001       City of London 001A 532123 181632 -0.097140 51.51816\n2 E01000002       City of London 001B 532480 181715 -0.091970 51.51882\n3 E01000003       City of London 001C 532239 182033 -0.095320 51.52174\n4 E01000005       City of London 001E 533581 181283 -0.076270 51.51468\n5 E01000006 Barking and Dagenham 016A 544994 184274  0.089317 51.53875\n                                GlobalID pop2021                           geom\n1 {1A259A13-A525-4858-9CB0-E4952BA01AF6}    1473 MULTIPOLYGON (((532105.3 18...\n2 {1233E433-0B0D-4807-8117-17A83C23960D}    1384 MULTIPOLYGON (((532634.5 18...\n3 {5163B7CB-4FFE-4F41-95B9-AA6CFC0508A3}    1613 MULTIPOLYGON (((532135.1 18...\n4 {2AF8015E-386E-456D-A45A-D0A223C340DF}    1101 MULTIPOLYGON (((533808 1807...\n5 {B492B45E-175E-4E77-B0B5-5B2FD6993EF4}    1842 MULTIPOLYGON (((545122 1843...\n [ reached 'max' / getOption(\"max.print\") -- omitted 1 rows ]\n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\n\n\nThe inspection shows that the POI dataset contains a wide variety of location types, with each point tagged under a main and alternative category, as provided by the Overture Maps Foundation via Meta and Microsoft. However, these tags may not be consistent across the dataset, so we will need to identify specific keywords to filter the main_category and alternate_category columns. We will start by filtering out all POIs where the word school features in the main_category column:\n\n\n\nR code\n\n# filter school poi data\npoi_schools &lt;- poi24 |&gt;\n    filter(str_detect(main_category, \"school\"))\n\n# inspect\nhead(unique(poi_schools$main_category), n = 50)\n\n\n [1] \"\\\"day_care_preschool\\\"\"              \"\\\"driving_school\\\"\"                 \n [3] \"\\\"elementary_school\\\"\"               \"\\\"school\\\"\"                         \n [5] \"\\\"language_school\\\"\"                 \"\\\"music_school\\\"\"                   \n [7] \"\\\"specialty_school\\\"\"                \"\\\"preschool\\\"\"                      \n [9] \"\\\"dance_school\\\"\"                    \"\\\"high_school\\\"\"                    \n[11] \"\\\"drama_school\\\"\"                    \"\\\"cooking_school\\\"\"                 \n[13] \"\\\"middle_school\\\"\"                   \"\\\"vocational_and_technical_school\\\"\"\n[15] \"\\\"art_school\\\"\"                      \"\\\"private_school\\\"\"                 \n[17] \"\\\"religious_school\\\"\"                \"\\\"nursing_school\\\"\"                 \n[19] \"\\\"montessori_school\\\"\"               \"\\\"public_school\\\"\"                  \n[21] \"\\\"cosmetology_school\\\"\"              \"\\\"medical_school\\\"\"                 \n[23] \"\\\"engineering_schools\\\"\"             \"\\\"massage_school\\\"\"                 \n[25] \"\\\"business_schools\\\"\"                \"\\\"law_schools\\\"\"                    \n[27] \"\\\"medical_sciences_schools\\\"\"        \"\\\"sports_school\\\"\"                  \n[29] \"\\\"flight_school\\\"\"                  \n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\nThis is still a very large list, and not all POIs containing the string school should be included. However, this initial selection gives us a more manageable list from which we can choose the relevant tags. Once we have made our selections, we can further filter the dataset accordingly as well as clip the dataset to the administrative boundaries of Lambeth.\n\n\n\nR code\n\n# remove quotes for easier processing\npoi_schools &lt;- poi_schools |&gt;\n    mutate(main_category = str_replace_all(main_category, \"\\\"\", \"\"))\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(main_category == \"elementary_school\" | main_category == \"high_school\" |\n        main_category == \"middle_school\" | main_category == \"private_school\" | main_category ==\n        \"public_school\" | main_category == \"school\")\n\n# filter school poi data\nlambeth &lt;- borough |&gt;\n    filter(name == \"Lambeth\")\n\npoi_schools &lt;- poi_schools |&gt;\n    st_intersection(lambeth) |&gt;\n    select(1:11)\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n# inspect\npoi_schools\n\nSimple feature collection with 141 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 169846.4 xmax: 533065.9 ymax: 180398\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                 id\n6  08f194ad1a394235035f3ab7c2e4721d\n7  08f194ad1a8da734035945d69c357ddd\n8  08f194ad1abb648603defd9d76b4c314\n27 08f194ad130f0cd303c1c9f9b42438f8\n                                               primary_name     main_category\n6                         \"Woodmansterne Children's Centre\" elementary_school\n7   \"Immanuel & St Andrew Church of England Primary School\"            school\n8  \"Monkey Puzzle Day Nursery & Preschool Streatham Common\"            school\n27                                     \"Campsbourne School\"            school\n                        alternate_category                   address locality\n6                         school|education            \"Stockport Rd\"     &lt;NA&gt;\n7              elementary_school|education           \"Northanger Rd\"     &lt;NA&gt;\n8  education|public_service_and_government \"496 Streatham High Road\" \"London\"\n27                               education                      &lt;NA&gt; \"London\"\n     postcode region country source   source_record_id\n6  \"SW16 5XE\"   &lt;NA&gt;    \"GB\" \"meta\"  \"114577088601307\"\n7  \"SW16 5SL\"   &lt;NA&gt;    \"GB\" \"meta\"  \"128479257200832\"\n8  \"SW16 3QB\"  \"ENG\"    \"GB\" \"meta\" \"1092187950854118\"\n27       &lt;NA&gt;   &lt;NA&gt;    \"GB\" \"meta\"  \"114411542481619\"\n                        geom\n6  POINT (529701.5 169846.4)\n7  POINT (530016.4 170574.1)\n8  POINT (530208.6 170587.9)\n27 POINT (528819.8 174228.7)\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nThis is still a rather long list and likely inaccurate. According to Lambeth Council Education Statistics, there should be 80 primary and secondary schools across the borough. We can use the alternate_category column to further narrow down our results.\n\n\n\n\n\n\nYou can inspect the different tags and their frequencies easily by creating a frequency table: table(poi_schools$alternate_category).\n\n\n\n\n\n\nR code\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(str_detect(alternate_category, \"elementary_school\") | str_detect(alternate_category,\n        \"high_school\") | str_detect(alternate_category, \"middle_school\") | str_detect(alternate_category,\n        \"private_school\") | str_detect(alternate_category, \"public_school\"))\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 58 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 170025.3 xmax: 532897.2 ymax: 179678.2\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                id\n1 08f194ad1a8da734035945d69c357ddd\n2 08f194ad1a70460d037da737c256001b\n3 08f194ad1c2dc81c032e9e0aa296a8d1\n4 08f194ad1e4cec5903fafb7496a2d2f3\n                                             primary_name     main_category\n1 \"Immanuel & St Andrew Church of England Primary School\"            school\n2                                \"Granton Primary School\" elementary_school\n3                 \"Kingswood Primary School (Upper Site)\" elementary_school\n4                              \"Battersea Grammar School\"            school\n           alternate_category          address locality   postcode region\n1 elementary_school|education  \"Northanger Rd\"     &lt;NA&gt; \"SW16 5SL\"   &lt;NA&gt;\n2        school|public_school     \"Granton Rd\"     &lt;NA&gt; \"SW16 5AN\"   &lt;NA&gt;\n3          school|high_school \"193 Gipsy Road\" \"London\"   \"SE27 9\"  \"ENG\"\n4       high_school|education             &lt;NA&gt; \"London\"       &lt;NA&gt;   &lt;NA&gt;\n  country source  source_record_id                      geom\n1    \"GB\" \"meta\" \"128479257200832\" POINT (530016.4 170574.1)\n2    \"GB\" \"meta\" \"235737420093504\" POINT (529299.7 170025.3)\n3    \"GB\" \"meta\" \"110066125723254\" POINT (532897.2 171498.4)\n4    \"GB\" \"meta\" \"103107239728950\" POINT (529523.9 172310.9)\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nSince the POI dataset is compiled from various open sources, the data quality is not guaranteed. Some schools may be missing, while others could be duplicated, perhaps under slightly different names or because different buildings have been assigned separate point locations. However, it is unlikely that more than one school would share the same postcode. Therefore, we will use postcode information (where available) to finalise our school selection and remove any likely duplicates.\n\n\n\nR code\n\n# identify duplicate postcodes\npoi_schools &lt;- poi_schools |&gt;\n    group_by(postcode) |&gt;\n    mutate(rank = rank(primary_name)) |&gt;\n    ungroup()\n\n# filter school poi data\npoi_schools &lt;- poi_schools |&gt;\n    filter(is.na(postcode) | rank == 1) |&gt;\n    select(-rank)\n\n# inspect\npoi_schools\n\n\nSimple feature collection with 54 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 528635.7 ymin: 170025.3 xmax: 532897.2 ymax: 179678.2\nProjected CRS: OSGB36 / British National Grid\n# A tibble: 54 × 12\n   id    primary_name main_category alternate_category address locality postcode\n   &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;              &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n 1 08f1… \"\\\"Immanuel… school        elementary_school… \"\\\"Nor…  &lt;NA&gt;    \"\\\"SW16…\n 2 08f1… \"\\\"Granton … elementary_s… school|public_sch… \"\\\"Gra…  &lt;NA&gt;    \"\\\"SW16…\n 3 08f1… \"\\\"Kingswoo… elementary_s… school|high_school \"\\\"193… \"\\\"Lond… \"\\\"SE27…\n 4 08f1… \"\\\"Batterse… school        high_school|educa…  &lt;NA&gt;   \"\\\"Lond…  &lt;NA&gt;   \n 5 08f1… \"\\\"St Bede'… school        elementary_school… \"\\\"St …  &lt;NA&gt;    \"\\\"SW12…\n 6 08f1… \"\\\"St Leona… school        elementary_school… \"\\\"42 … \"\\\"Lond… \"\\\"SW16…\n 7 08f1… \"\\\"Richard … elementary_s… college_universit… \"\\\"New…  &lt;NA&gt;    \"\\\"SW2 …\n 8 08f1… \"\\\"Henry Ca… school        high_school|eleme… \"\\\"Hyd…  &lt;NA&gt;    \"\\\"SW12…\n 9 08f1… \"\\\"South Ba… school        high_school|b2b_s… \"\\\"56 … \"\\\"Lond… \"\\\"SW2 …\n10 08f1… \"\\\"Glenbroo… elementary_s… school|public_sch… \"\\\"Cla…  &lt;NA&gt;    \"\\\"SW4 …\n# ℹ 44 more rows\n# ℹ 5 more variables: region &lt;chr&gt;, country &lt;chr&gt;, source &lt;chr&gt;,\n#   source_record_id &lt;chr&gt;, geom &lt;POINT [m]&gt;\n\n\nAlthough we now have fewer schools than we had expected, either due to overly restrictive filtering of tags or because some school locations are not recorded in the dataset, we will proceed with the current data.\n\n\n\n\n\n\nVariable preparation can be a time-consuming process that often necessitates a more extensive exploratory analysis to ensure sufficient data quality. This may involve sourcing additional data to supplement your existing dataset.\n\n\n\nWe can now use a similar approach to approximate the locations of fast food outlets in the Borough.\n\n\n\nR code\n\n# filter fast food poi data\npoi_fastfood &lt;- poi24 |&gt;\n    filter(str_detect(main_category, \"fast_food_restaurant\") | str_detect(alternate_category,\n        \"fast_food_restaurant\") | str_detect(alternate_category, \"chicken_restaurant\") |\n        str_detect(alternate_category, \"burger_restaurant\"))\n\n# inspect\npoi_fastfood\n\n\nSimple feature collection with 1444 features and 11 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 526666.3 ymin: 168272.9 xmax: 535546.9 ymax: 182554\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n                                id     primary_name          main_category\n1 08f194ada9716b86030eab41bbd4207e  \"Gorgeous Grub\"    \"burger_restaurant\"\n2 08f194ada9449a8a0345a466a0a6ece9        \"Lidl GB\"          \"supermarket\"\n3 08f194ada944daa80328c6604dab3503     \"Moss Bros.\" \"men's_clothing_store\"\n4 08f194ada932ad8603db11bbb7f953a7 \"Livi's Cuisine\"   \"african_restaurant\"\n                  alternate_category                          address  locality\n1 eat_and_drink|fast_food_restaurant          \"1 Prince Georges Road\"  \"London\"\n2        retail|fast_food_restaurant                  \"Colliers Wood\"  \"London\"\n3               fast_food_restaurant \"Unit 5, Tandem Shopping Centre\"  \"London\"\n4       caterer|fast_food_restaurant                   \"1 Locks Lane\" \"Mitcham\"\n    postcode region country source  source_record_id\n1   \"SW19 2\"  \"ENG\"    \"GB\" \"meta\" \"232538816864698\"\n2 \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\" \"111430837210163\"\n3 \"SW19 2TY\"   &lt;NA&gt;    \"GB\" \"meta\" \"478090646011341\"\n4    \"CR4 2\"  \"ENG\"    \"GB\" \"meta\" \"231745500530140\"\n                            geom\n1 MULTIPOINT ((526913.4 16984...\n2 MULTIPOINT ((526922.2 16988...\n3 MULTIPOINT ((526945.5 16992...\n4 MULTIPOINT ((527970.3 16955...\n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\nLet’s map both dataset to get an idea of how the data look like:\n\n\n\nR code\n\n# combine for mapping\npoi_schools &lt;- poi_schools |&gt;\n  mutate(type = \"School\")\npoi_fastfood &lt;- poi_fastfood |&gt;\n  mutate(type = \"Fast food\")\npoi_lambeth &lt;- rbind(poi_schools, poi_fastfood)\n\n# shape, polygon\ntm_shape(lambeth) +\n\n  # specify column, classes\n  tm_polygons(\n    col = \"#f0f0f0\",\n  ) +\n\n  # shape, points\n  tm_shape(poi_lambeth) +\n\n  # specify column, colours\n  tm_dots(\n    col = \"type\",\n    size = 0.05,\n    palette = c(\"#beaed4\", \"#fdc086\"),\n    title = \"POI type\"\n  ) +\n\n  # set layout\n  tm_layout(\n    legend.outside = TRUE,\n    legend.position = c(\"right\", \"bottom\"),\n    frame = FALSE\n  )\n\n\n\n\n\nFigure 1: Extracted school and fast food locations for Lambeth.\n\n\n\n\n\n\n\nIn addition to the locations of interest, we need network data to assess the accessibility of schools in relation to fast food outlets. We will use OpenStreetMap to extract road segment data. Similar to the POI dataset, OSM uses key and value tags to categorise the features within its dataset.\n\n\n\n\n\n\nOpenStreetMap (OSM) is a free, editable map of the world, but its coverage is uneven globally. However, the accuracy and quality of the data can at times be questionable, with details such as road types and speed limits missing. The OpenStreetMap Wiki provides more details on the tagging system.\n\n\n\nTo download the Lambeth road network dataset, we first need to define our bounding box coordinates. We will then use these coordinates in our OSM query to extract specific types of road segments within the defined search area. Our focus will be on selecting all OSM features with the highway tag that are likely to be used by pedestrians (e.g. excluding motorways).\n\n\n\nR code\n\n# define our bbox coordinates, use WGS84\nbbox_lambeth &lt;- poi24 |&gt;\n    st_transform(4326) |&gt;\n    st_bbox()\n\n# osm query\nosm_network &lt;- opq(bbox = bbox_lambeth) |&gt;\n    add_osm_feature(key = \"highway\", value = c(\"primary\", \"secondary\", \"tertiary\",\n        \"residential\", \"path\", \"footway\", \"unclassified\", \"living_street\", \"pedestrian\")) |&gt;\n    osmdata_sf()\n\n\n\n\n\n\n\n\nIn some cases, the OSM query may return an error, particularly when multiple users from the same location are executing the exact same query. If so, you can download a prepared copy of the data here: [Download].\nYou can load this copy into R through load('data/London-OSM-Roads.RData')\n\n\n\nThe returned osm_network object contains a variety of elements with the specified tags. Our next step is to extract the spatial data from this object to create our road network dataset. Specifically, we will extract the edges of the network, which represent the lines of the roads, as well as the nodes, which represent the points where the roads start, end, or intersect.\n\n\n\nR code\n\n# extract the nodes, with their osm_id.\nosm_network_nodes &lt;- osm_network$osm_points[, \"osm_id\"]\n\n# extract the edges\nosm_network_edges &lt;- osm_network$osm_lines[, c(\"osm_id\", \"name\", \"highway\", \"maxspeed\",\n    \"oneway\")]\n\n# inspect\nhead(osm_network_nodes)\n\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -0.1541499 ymin: 51.52434 xmax: -0.1457924 ymax: 51.52698\nGeodetic CRS:  WGS 84\n      osm_id                    geometry\n78112  78112 POINT (-0.1457924 51.52698)\n99878  99878 POINT (-0.1529787 51.52434)\n99879  99879 POINT (-0.1532934 51.52482)\n99880  99880 POINT (-0.1535802 51.52508)\n99882  99882 POINT (-0.1541499 51.52567)\n99883  99883 POINT (-0.1541362 51.52598)\n\n# inspect\nhead(osm_network_edges)\n\nSimple feature collection with 6 features and 5 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -0.1398347 ymin: 51.50608 xmax: -0.0821093 ymax: 51.5246\nGeodetic CRS:  WGS 84\n         osm_id                 name     highway maxspeed oneway\n31030     31030          Grafton Way     primary   20 mph    yes\n31039     31039 Tottenham Court Road     primary   20 mph   &lt;NA&gt;\n31959     31959     Cleveland Street residential   20 mph    yes\n554369   554369  King William Street    tertiary   20 mph    yes\n554526   554526     Fenchurch Street    tertiary   20 mph   &lt;NA&gt;\n1530592 1530592  Borough High Street     primary   30 mph    yes\n                              geometry\n31030   LINESTRING (-0.1349153 51.5...\n31039   LINESTRING (-0.1303693 51.5...\n31959   LINESTRING (-0.139512 51.52...\n554369  LINESTRING (-0.08745 51.511...\n554526  LINESTRING (-0.085135 51.51...\n1530592 LINESTRING (-0.0882957 51.5...\n\n\nWe can quickly map the edges to see how the road network looks like:\n\n\n\nR code\n\n# shape, polygon\ntm_shape(osm_network_edges) +\n\n  # specify column, classes\n  tm_lines(\n    col = \"#bdbdbd\",\n    lwd = 0.2,\n  ) +\n\n  # shape, polygon\n  tm_shape(lambeth) +\n\n  # specify column, classes\n  tm_borders(\n    col = \"#252525\",\n    lwd = 2\n  ) +\n\n  # set legend\n  tm_add_legend(\n    type = \"line\",\n    labels = \"Road segments\",\n    col = \"#bdbdbd\"\n  ) +\n\n  tm_add_legend(\n    type = \"line\",\n    labels = \"Outline Lambeth\",\n    col = \"#252525\"\n  ) +\n\n  # set layout\n  tm_layout(\n    frame = FALSE,\n    legend.outside = TRUE,\n    legend.position = c(\"right\", \"bottom\"),\n  )\n\n\n\n\n\nFigure 2: Extracted road network data for Lambeth."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Principles of Spatial Analysis",
    "section": "",
    "text": "Week\nSection\nTopic\n\n\n\n\n1\nFoundational Concepts\nSpatial analysis for data science\n\n\n2\nFoundational Concepts\nGraphical representation of spatial data\n\n\n3\nFoundational Concepts\nSpatial autocorrelation\n\n\n4\nRaster data\nSuitability Mapping I\n\n\n5\nRaster data\nSuitability Mapping II\n\n\n\nReading week\nReading week\n\n\n6\nRaster data\nGeostatistics using Kriging\n\n\n7\nApplied Spatial Analysis\nGeodemographics\n\n\n8\nApplied Spatial Analysis\nAccessibility analysis\n\n\n9\nSpatial models\nSpatial models I\n\n\n10\nSpatial models\nSpatial models II\n\n\n\n\n\n\n\n\n\nThis GitHub resrouces has been updated for the 2024-2025 academic year. The content for 2023-2024 has been archived and can be found here: [Link]\n\n\n\n\n\n\n\n\n\n\n\nThis year’s version features the following major updates:\n\nSecond full rewrite of the workbook using Quarto.\nFully updated geodemographics content drawing on the London Output Area Classification.\nUpdated transport network analysis content using Overture Point of Interest data.\n\n\n\n\n\n\n\nThis workbook is created using the Quarto publishing system. Elements of this workbook are partially based on and modified from:\n\nThe GEOG114: Principles of Spatial Analysis 2023-2024 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2022-2023 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2021-2022 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2020-2021 workbook by Justin van Dijk\n\nThe datasets used in this workbook contain:\n\nData from Office for National Statistics licensed under the Open Government Licence v.3.0\nOS data © Crown copyright and database right [2024]"
  },
  {
    "objectID": "index.html#major-updates",
    "href": "index.html#major-updates",
    "title": "Principles of Spatial Analysis",
    "section": "",
    "text": "This year’s version features the following major updates:\n\nSecond full rewrite of the workbook using Quarto.\nFully updated geodemographics content drawing on the London Output Area Classification.\nUpdated transport network analysis content using Overture Point of Interest data."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Principles of Spatial Analysis",
    "section": "",
    "text": "This workbook is created using the Quarto publishing system. Elements of this workbook are partially based on and modified from:\n\nThe GEOG114: Principles of Spatial Analysis 2023-2024 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2022-2023 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2021-2022 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2020-2021 workbook by Justin van Dijk\n\nThe datasets used in this workbook contain:\n\nData from Office for National Statistics licensed under the Open Government Licence v.3.0\nOS data © Crown copyright and database right [2024]"
  }
]