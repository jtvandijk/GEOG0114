[
  {
    "objectID": "01-geodemographics.html",
    "href": "01-geodemographics.html",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "This week we will turn to geodemographic classification. Geodemographic classification is a method used to categorise geographic areas and the people living in them based on demographic, socioeconomic, and sometimes lifestyle characteristics. This approach combines geographic information with demographic data to create profiles of different neighborhoods.\n\n\nYou can download the slides of this week’s lecture here: [Link].\n\n\n\n\n\n\nLongley, P. A. 2012. Geodemographics and the practices of geographic information science. International Journal of Geographical Information Science 26(12): 2227-2237. [Link]\nSingleton, A. and Longley, P. A. 2024. Classifying and mapping residential structure through the London Output Area Classification. Environment and Planning B: Urban Analytics and City Science 51(5): 1153-1164. [Link]\nWyszomierski, J., Longley, P. A., and Singleton, A. et al. 2024. A neighbourhood Output Area Classification from the 2021 and 2022 UK censuses. The Geographical Journal. 190(2): e12550. [Link]\n\n\n\n\n\nFränti, P. and Sieronoja, S. 2019. How much can k-means be improved by using better initialization and repeats? Pattern Recognition 93: 95-112. [Link]\nSingleton, A. and Spielman, S. 2014. The past, present, and future of geodemographic research in the United States and United Kingdom. The Professional Geographer 66(4): 558-567. [Link]\n\n\n\n\n\nToday, we will create our own geodemographic classification to examine demographic clusters across London. Specifically, we will focus on age group, self-identified ethnicity, and country of birth. Additionally, we will include data on an individual’s first or preferred language. The data represent all usual residents as recorded in the 2021 Census for England and Wales, and have been extracted using the Custom Dataset Tool.\nYou can download copies of each file via the links below. Save these files in your project folder under data.\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon LSOA Census 2021 Age Groups\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Country of Birth\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Ethnicity\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Main Language\ncsv\nDownload\n\n\n\n\n\n\n\n\n\nTo download a csv file that is hosted on GitHub, click on the Download raw file button on the top right of your screen and it should download directly to your computer.\n\n\n\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(tmap)\n\n\nNext, we can load the individual csv files into R.\n\n\n\nR code\n\n# load age data\nlsoa_age &lt;- read_csv('data/London-LSOA-AgeGroup.csv')\n\n\nRows: 24970 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Age (5 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load country of birth data\nlsoa_cob &lt;- read_csv('data/London-LSOA-Country-of-Birth.csv')\n\nRows: 39952 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Country of birth (8 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load ethnicity data\nlsoa_eth &lt;- read_csv('data/London-LSOA-Ethnicity.csv')\n\nRows: 99880 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Ethnic group (20 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load language data\nlsoa_lan &lt;- read_csv('data/London-LSOA-MainLanguage.csv')\n\nRows: 54934 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Main language (11 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nIf using a Windows machine, you may need to substitute your forward-slashes (/) with two backslashes (\\\\) whenever you are dealing with file paths.\n\n\n\nLet us have a look at the data:\n\n\n\nR code\n\n# inspect age data\nhead(lsoa_age)\n\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Age (5 categories) C…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                         1\n2 E01000001                        City of London 001A                         2\n3 E01000001                        City of London 001A                         3\n4 E01000001                        City of London 001A                         4\n5 E01000001                        City of London 001A                         5\n6 E01000002                        City of London 001B                         1\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Age (5 categories) Code`\n# ℹ 2 more variables: `Age (5 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n# inspect country of birth data\nhead(lsoa_cob)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Country of birth (8 …³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Country of birth (8 categories) Code`\n# ℹ 2 more variables: `Country of birth (8 categories)` &lt;chr&gt;,\n#   Observation &lt;dbl&gt;\n\n# inspect ethnicity data\nhead(lsoa_eth)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Ethnic group (20 cat…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Ethnic group (20 categories) Code`\n# ℹ 2 more variables: `Ethnic group (20 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n# inspect language data\nhead(lsoa_lan)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Main language (11 ca…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Main language (11 categories) Code`\n# ℹ 2 more variables: `Main language (11 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\nTo identify geodemographic clusters in our dataset, we will use an unsupervised machine learning technique called \\(k\\)-means. \\(k\\)-means aims to partition a set of standardised observations into a specified number of clusters (\\(k\\)), where each observation is assigned to the cluster with the nearest mean. In this context, a cluster refers to a collection of data points grouped together based on certain similarities. To do this we first need to prepare the individual datasets, as well as transform and standardise the input variables.\n\n\nBecause all the data are stored in long format, with each London LSOA having separate entries for each category, we need to transform it into a wide format. Additionally, we need to clean up the column names to align with general R naming conventions, which can be done using the janitor package.\nWe will begin with the age dataframe:\n\n\n\nR code\n\n# clean names \nlsoa_age &lt;- lsoa_age |&gt;\n  clean_names()\n\n# pivot\nlsoa_age &lt;- lsoa_age |&gt;\n  pivot_wider(id_cols = 'lower_layer_super_output_areas_code',\n              names_from = 'age_5_categories',\n              values_from = 'observation') \n\n# clean names\nlsoa_age &lt;- lsoa_age |&gt;\n  clean_names()\n\n\n\n\n\n\n\n\nThe code above uses a pipe function: |&gt;. The pipe operator allows you to pass the output of one function directly into the next, streamlining your code. While it might seem a bit confusing at first, you will find that it makes your code faster to write and easier to read. More importantly, it reduces the need to create multiple intermediate variables to store outputs.\n\n\n\n\n\n\n\n\n\nBe sure to inspect your dataframes between steps to understand exactly what the code is doing.\n\n\n\nTo account for the non-uniformity of the area units, we further need to convert the observations to percentages and only retain those columns that are likely to be meaningful in the context of the classification:\n\n\n\nR code\n\n# total observations\nlsoa_age &lt;- lsoa_age |&gt;\n    rowwise() |&gt;\n    mutate(age_pop = sum(across(2:6)))\n\n# total proportions, select columns\nlsoa_age &lt;- lsoa_age |&gt;\n    mutate(across(2:6, ~./age_pop)) |&gt;\n    select(1:6)\n\n# inspect\nhead(lsoa_age)\n\n\n# A tibble: 6 × 6\n# Rowwise: \n  lower_layer_super_output_areas_code aged_15_years_and_un…¹ aged_16_to_24_years\n  &lt;chr&gt;                                                &lt;dbl&gt;               &lt;dbl&gt;\n1 E01000001                                           0.0846              0.0744\n2 E01000002                                           0.0621              0.0889\n3 E01000003                                           0.0682              0.0706\n4 E01000005                                           0.127               0.178 \n5 E01000006                                           0.224               0.120 \n6 E01000007                                           0.257               0.103 \n# ℹ abbreviated name: ¹​aged_15_years_and_under\n# ℹ 3 more variables: aged_25_to_34_years &lt;dbl&gt;, aged_35_to_49_years &lt;dbl&gt;,\n#   aged_50_years_and_over &lt;dbl&gt;\n\n\nThis looks much better. We can do the same for the country of birth data:\n\n\n\nR code\n\n# prepare country of birth data\nlsoa_cob &lt;- lsoa_cob |&gt;\n    clean_names() |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"country_of_birth_8_categories\",\n        values_from = \"observation\") |&gt;\n    clean_names()\n\n# proportions, select columns\nlsoa_cob &lt;- lsoa_cob |&gt;\n    rowwise() |&gt;\n    mutate(cob_pop = sum(across(2:9))) |&gt;\n    mutate(across(2:9, ~./cob_pop)) |&gt;\n    select(-2, -10)\n\n\nAnd we can do the same for the ethnicity and language datasets:\n\n\n\nR code\n\n# prepare ethnicity data\nlsoa_eth &lt;- lsoa_eth |&gt;\n  clean_names() |&gt;\n  pivot_wider(id_cols = 'lower_layer_super_output_areas_code',\n              names_from = 'ethnic_group_20_categories',\n              values_from = 'observation') |&gt;\n  clean_names()\n\n# proportions, select columns\nlsoa_eth &lt;- lsoa_eth |&gt;\n  rowwise() |&gt;\n  mutate(eth_pop = sum(across(2:21))) |&gt;\n  mutate(across(2:21, ~ . / eth_pop )) |&gt;\n  select(-2,-22)\n\n# prepare language data\nlsoa_lan &lt;- lsoa_lan |&gt;\n  clean_names() |&gt;\n  pivot_wider(id_cols = 'lower_layer_super_output_areas_code',\n              names_from = 'main_language_11_categories',\n              values_from = 'observation') |&gt;\n  clean_names()\n\n# proportions, select columns\nlsoa_lan &lt;- lsoa_lan |&gt;\n  rowwise() |&gt;\n  mutate(lan_pop = sum(across(2:12))) |&gt;\n  mutate(across(2:12, ~ . / lan_pop )) |&gt;\n  select(-2,-11,-13)\n\n\nWe now have four separate datasets, each containing the proportions of usual residents classified into different groups based on age, ethnicity, language, and country of birth.\n\n\n\nWhere we initially selected variables from different demographic domains, not all variables may be suitable for inclusion. Firstly, the variables need to exhibit sufficient heterogeneity to ensure they capture meaningful differences between observations. Secondly, variables should not be highly correlated with one another, as this redundancy can skew the clustering results. Ensuring acceptable correlation between variables helps maintain the diversity of information and improves the robustness of the clustering outcome.\n\n\n\n\n\n\nVariable selection is often a time-consuming process that requires a combination of domain knowledge and more extensive exploratory analysis than is covered in this practical.\n\n\n\nA straightforward yet effective method to examine the distribution of our variables is to create boxplots for each variable. This can be efficiently achieved by using facet_wrap() to generate a matrix of panels, allowing us to visualise all variables in a single view. For more details on facet_wrap(), you can refer to the ggplot2 documentation.\n\n\n\nR code\n\n# wide to long\nlsoa_age_wd &lt;- lsoa_age |&gt;\n    pivot_longer(cols = c(2:5), names_to = \"variable\", values_to = \"value\")\n\n# facet age\nggplot(lsoa_age_wd, aes(y = value)) + geom_boxplot() + facet_wrap(~variable, ncol = 2) +\n    theme_minimal()\n\n\n\n\n\nFigure 1: Boxplots of the distribution of the age dataset.\n\n\n\n\nWhen repeating this process for the birth, ethnicity, and language variables, you will notice that some variables have a very limited distribution. Specifically, some variables may have a value of 0 for the majority of London LSOAs. As a rule of thumb, we will retain only those variables where at least 25% of the LSOAs have values different from 0.\n\n\n\n\n\n\nThis threshold of 25% is arbitrary, and in practice, more thorough consideration should be given when deciding whether to include or exclude a variable.\n\n\n\n\n\n\nR code\n\n# join\nlsoa_df &lt;- lsoa_age |&gt;\n    left_join(lsoa_cob, by = \"lower_layer_super_output_areas_code\") |&gt;\n    left_join(lsoa_eth, by = \"lower_layer_super_output_areas_code\") |&gt;\n    left_join(lsoa_lan, by = \"lower_layer_super_output_areas_code\")\n\n\n\n\n\n\n\n\nVariable selection is often a time-consuming process that requires a combination of domain knowledge and more extensive exploratory analysis than is covered in this practical.\n\n\n\n\n\n\nIf the input data are heavily skewed or contain outliers, \\(k\\)-means may produce less meaningful clusters. While normality is not required, it has been common to do this nonetheless. More important is to standardise the input variables, especially when they are measured on different scales. This ensures that each variable contributes equally to the clustering process.\n\n\n\n\n\n\nSince our variables are all expressed as proportions in this example, range standardisation is not technically required.\n\n\n\n\n\n\n\nThe creation of a geodemographic classification is an iterative process. This typically includes adding or removing variables, adjusting the number of clusters, and grouping data in different ways to achieve the most meaningful segmentation. If you want to refine your clustering solution, you can re-run the analysis with different variables or cluster numbers by simply updating your code. However, automating parts of this process with a function would streamline the workflow and make it more efficient.\nTry to create a simple R function that:\n\nTakes at least three arguments: a data frame containing the input data, the number of clusters you want, and a list of input variables.\nExecutes a k-means clustering on the specified input variables and number of clusters.\nGenerates a csv file that contains a table of means for each cluster in the solution.\n\n\n\n\n\n\n\n\nYour function could be structured like this: run-kmeans(df, k, vars), where df is your input dataframe, k is the number of clusters, and vars is a list of input variables.\nFor a more in-depth discussion on constructing functions in R, refer to Hadley Wickham’s R for Data Science Chapter on Functions.\n\n\n\n\n\n\n\n\nHaving finished this tutorial, you should now understand the basics of a geodemographic classification. In addition, you should now be able to write simple functions. That is all for this week!"
  },
  {
    "objectID": "01-geodemographics.html#lecture-w07",
    "href": "01-geodemographics.html#lecture-w07",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "You can download the slides of this week’s lecture here: [Link]."
  },
  {
    "objectID": "01-geodemographics.html#reading-w07",
    "href": "01-geodemographics.html#reading-w07",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "Longley, P. A. 2012. Geodemographics and the practices of geographic information science. International Journal of Geographical Information Science 26(12): 2227-2237. [Link]\nSingleton, A. and Longley, P. A. 2024. Classifying and mapping residential structure through the London Output Area Classification. Environment and Planning B: Urban Analytics and City Science 51(5): 1153-1164. [Link]\nWyszomierski, J., Longley, P. A., and Singleton, A. et al. 2024. A neighbourhood Output Area Classification from the 2021 and 2022 UK censuses. The Geographical Journal. 190(2): e12550. [Link]\n\n\n\n\n\nFränti, P. and Sieronoja, S. 2019. How much can k-means be improved by using better initialization and repeats? Pattern Recognition 93: 95-112. [Link]\nSingleton, A. and Spielman, S. 2014. The past, present, and future of geodemographic research in the United States and United Kingdom. The Professional Geographer 66(4): 558-567. [Link]"
  },
  {
    "objectID": "01-geodemographics.html#london-output-area-classification",
    "href": "01-geodemographics.html#london-output-area-classification",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "Today, we will create our own geodemographic classification to examine demographic clusters across London. Specifically, we will focus on age group, self-identified ethnicity, and country of birth. Additionally, we will include data on an individual’s first or preferred language. The data represent all usual residents as recorded in the 2021 Census for England and Wales, and have been extracted using the Custom Dataset Tool.\nYou can download copies of each file via the links below. Save these files in your project folder under data.\n\n\n\nFile\nType\nLink\n\n\n\n\nLondon LSOA Census 2021 Age Groups\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Country of Birth\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Ethnicity\ncsv\nDownload\n\n\nLondon LSOA Census 2021 Main Language\ncsv\nDownload\n\n\n\n\n\n\n\n\n\nTo download a csv file that is hosted on GitHub, click on the Download raw file button on the top right of your screen and it should download directly to your computer.\n\n\n\nWe will start by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(tmap)\n\n\nNext, we can load the individual csv files into R.\n\n\n\nR code\n\n# load age data\nlsoa_age &lt;- read_csv('data/London-LSOA-AgeGroup.csv')\n\n\nRows: 24970 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Age (5 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load country of birth data\nlsoa_cob &lt;- read_csv('data/London-LSOA-Country-of-Birth.csv')\n\nRows: 39952 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Country of birth (8 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load ethnicity data\nlsoa_eth &lt;- read_csv('data/London-LSOA-Ethnicity.csv')\n\nRows: 99880 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Ethnic group (20 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# load language data\nlsoa_lan &lt;- read_csv('data/London-LSOA-MainLanguage.csv')\n\nRows: 54934 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Lower layer Super Output Areas Code, Lower layer Super Output Areas...\ndbl (2): Main language (11 categories) Code, Observation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nIf using a Windows machine, you may need to substitute your forward-slashes (/) with two backslashes (\\\\) whenever you are dealing with file paths.\n\n\n\nLet us have a look at the data:\n\n\n\nR code\n\n# inspect age data\nhead(lsoa_age)\n\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Age (5 categories) C…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                         1\n2 E01000001                        City of London 001A                         2\n3 E01000001                        City of London 001A                         3\n4 E01000001                        City of London 001A                         4\n5 E01000001                        City of London 001A                         5\n6 E01000002                        City of London 001B                         1\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Age (5 categories) Code`\n# ℹ 2 more variables: `Age (5 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n# inspect country of birth data\nhead(lsoa_cob)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Country of birth (8 …³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Country of birth (8 categories) Code`\n# ℹ 2 more variables: `Country of birth (8 categories)` &lt;chr&gt;,\n#   Observation &lt;dbl&gt;\n\n# inspect ethnicity data\nhead(lsoa_eth)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Ethnic group (20 cat…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Ethnic group (20 categories) Code`\n# ℹ 2 more variables: `Ethnic group (20 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n# inspect language data\nhead(lsoa_lan)\n\n# A tibble: 6 × 5\n  Lower layer Super Output Areas…¹ Lower layer Super Ou…² Main language (11 ca…³\n  &lt;chr&gt;                            &lt;chr&gt;                                   &lt;dbl&gt;\n1 E01000001                        City of London 001A                        -8\n2 E01000001                        City of London 001A                         1\n3 E01000001                        City of London 001A                         2\n4 E01000001                        City of London 001A                         3\n5 E01000001                        City of London 001A                         4\n6 E01000001                        City of London 001A                         5\n# ℹ abbreviated names: ¹​`Lower layer Super Output Areas Code`,\n#   ²​`Lower layer Super Output Areas`, ³​`Main language (11 categories) Code`\n# ℹ 2 more variables: `Main language (11 categories)` &lt;chr&gt;, Observation &lt;dbl&gt;\n\n\n\n\n\n\n\n\nYou can further inspect the results using the View() function.\n\n\n\nTo identify geodemographic clusters in our dataset, we will use an unsupervised machine learning technique called \\(k\\)-means. \\(k\\)-means aims to partition a set of standardised observations into a specified number of clusters (\\(k\\)), where each observation is assigned to the cluster with the nearest mean. In this context, a cluster refers to a collection of data points grouped together based on certain similarities. To do this we first need to prepare the individual datasets, as well as transform and standardise the input variables.\n\n\nBecause all the data are stored in long format, with each London LSOA having separate entries for each category, we need to transform it into a wide format. Additionally, we need to clean up the column names to align with general R naming conventions, which can be done using the janitor package.\nWe will begin with the age dataframe:\n\n\n\nR code\n\n# clean names \nlsoa_age &lt;- lsoa_age |&gt;\n  clean_names()\n\n# pivot\nlsoa_age &lt;- lsoa_age |&gt;\n  pivot_wider(id_cols = 'lower_layer_super_output_areas_code',\n              names_from = 'age_5_categories',\n              values_from = 'observation') \n\n# clean names\nlsoa_age &lt;- lsoa_age |&gt;\n  clean_names()\n\n\n\n\n\n\n\n\nThe code above uses a pipe function: |&gt;. The pipe operator allows you to pass the output of one function directly into the next, streamlining your code. While it might seem a bit confusing at first, you will find that it makes your code faster to write and easier to read. More importantly, it reduces the need to create multiple intermediate variables to store outputs.\n\n\n\n\n\n\n\n\n\nBe sure to inspect your dataframes between steps to understand exactly what the code is doing.\n\n\n\nTo account for the non-uniformity of the area units, we further need to convert the observations to percentages and only retain those columns that are likely to be meaningful in the context of the classification:\n\n\n\nR code\n\n# total observations\nlsoa_age &lt;- lsoa_age |&gt;\n    rowwise() |&gt;\n    mutate(age_pop = sum(across(2:6)))\n\n# total proportions, select columns\nlsoa_age &lt;- lsoa_age |&gt;\n    mutate(across(2:6, ~./age_pop)) |&gt;\n    select(1:6)\n\n# inspect\nhead(lsoa_age)\n\n\n# A tibble: 6 × 6\n# Rowwise: \n  lower_layer_super_output_areas_code aged_15_years_and_un…¹ aged_16_to_24_years\n  &lt;chr&gt;                                                &lt;dbl&gt;               &lt;dbl&gt;\n1 E01000001                                           0.0846              0.0744\n2 E01000002                                           0.0621              0.0889\n3 E01000003                                           0.0682              0.0706\n4 E01000005                                           0.127               0.178 \n5 E01000006                                           0.224               0.120 \n6 E01000007                                           0.257               0.103 \n# ℹ abbreviated name: ¹​aged_15_years_and_under\n# ℹ 3 more variables: aged_25_to_34_years &lt;dbl&gt;, aged_35_to_49_years &lt;dbl&gt;,\n#   aged_50_years_and_over &lt;dbl&gt;\n\n\nThis looks much better. We can do the same for the country of birth data:\n\n\n\nR code\n\n# prepare country of birth data\nlsoa_cob &lt;- lsoa_cob |&gt;\n    clean_names() |&gt;\n    pivot_wider(id_cols = \"lower_layer_super_output_areas_code\", names_from = \"country_of_birth_8_categories\",\n        values_from = \"observation\") |&gt;\n    clean_names()\n\n# proportions, select columns\nlsoa_cob &lt;- lsoa_cob |&gt;\n    rowwise() |&gt;\n    mutate(cob_pop = sum(across(2:9))) |&gt;\n    mutate(across(2:9, ~./cob_pop)) |&gt;\n    select(-2, -10)\n\n\nAnd we can do the same for the ethnicity and language datasets:\n\n\n\nR code\n\n# prepare ethnicity data\nlsoa_eth &lt;- lsoa_eth |&gt;\n  clean_names() |&gt;\n  pivot_wider(id_cols = 'lower_layer_super_output_areas_code',\n              names_from = 'ethnic_group_20_categories',\n              values_from = 'observation') |&gt;\n  clean_names()\n\n# proportions, select columns\nlsoa_eth &lt;- lsoa_eth |&gt;\n  rowwise() |&gt;\n  mutate(eth_pop = sum(across(2:21))) |&gt;\n  mutate(across(2:21, ~ . / eth_pop )) |&gt;\n  select(-2,-22)\n\n# prepare language data\nlsoa_lan &lt;- lsoa_lan |&gt;\n  clean_names() |&gt;\n  pivot_wider(id_cols = 'lower_layer_super_output_areas_code',\n              names_from = 'main_language_11_categories',\n              values_from = 'observation') |&gt;\n  clean_names()\n\n# proportions, select columns\nlsoa_lan &lt;- lsoa_lan |&gt;\n  rowwise() |&gt;\n  mutate(lan_pop = sum(across(2:12))) |&gt;\n  mutate(across(2:12, ~ . / lan_pop )) |&gt;\n  select(-2,-11,-13)\n\n\nWe now have four separate datasets, each containing the proportions of usual residents classified into different groups based on age, ethnicity, language, and country of birth.\n\n\n\nWhere we initially selected variables from different demographic domains, not all variables may be suitable for inclusion. Firstly, the variables need to exhibit sufficient heterogeneity to ensure they capture meaningful differences between observations. Secondly, variables should not be highly correlated with one another, as this redundancy can skew the clustering results. Ensuring acceptable correlation between variables helps maintain the diversity of information and improves the robustness of the clustering outcome.\n\n\n\n\n\n\nVariable selection is often a time-consuming process that requires a combination of domain knowledge and more extensive exploratory analysis than is covered in this practical.\n\n\n\nA straightforward yet effective method to examine the distribution of our variables is to create boxplots for each variable. This can be efficiently achieved by using facet_wrap() to generate a matrix of panels, allowing us to visualise all variables in a single view. For more details on facet_wrap(), you can refer to the ggplot2 documentation.\n\n\n\nR code\n\n# wide to long\nlsoa_age_wd &lt;- lsoa_age |&gt;\n    pivot_longer(cols = c(2:5), names_to = \"variable\", values_to = \"value\")\n\n# facet age\nggplot(lsoa_age_wd, aes(y = value)) + geom_boxplot() + facet_wrap(~variable, ncol = 2) +\n    theme_minimal()\n\n\n\n\n\nFigure 1: Boxplots of the distribution of the age dataset.\n\n\n\n\nWhen repeating this process for the birth, ethnicity, and language variables, you will notice that some variables have a very limited distribution. Specifically, some variables may have a value of 0 for the majority of London LSOAs. As a rule of thumb, we will retain only those variables where at least 25% of the LSOAs have values different from 0.\n\n\n\n\n\n\nThis threshold of 25% is arbitrary, and in practice, more thorough consideration should be given when deciding whether to include or exclude a variable.\n\n\n\n\n\n\nR code\n\n# join\nlsoa_df &lt;- lsoa_age |&gt;\n    left_join(lsoa_cob, by = \"lower_layer_super_output_areas_code\") |&gt;\n    left_join(lsoa_eth, by = \"lower_layer_super_output_areas_code\") |&gt;\n    left_join(lsoa_lan, by = \"lower_layer_super_output_areas_code\")\n\n\n\n\n\n\n\n\nVariable selection is often a time-consuming process that requires a combination of domain knowledge and more extensive exploratory analysis than is covered in this practical.\n\n\n\n\n\n\nIf the input data are heavily skewed or contain outliers, \\(k\\)-means may produce less meaningful clusters. While normality is not required, it has been common to do this nonetheless. More important is to standardise the input variables, especially when they are measured on different scales. This ensures that each variable contributes equally to the clustering process.\n\n\n\n\n\n\nSince our variables are all expressed as proportions in this example, range standardisation is not technically required."
  },
  {
    "objectID": "01-geodemographics.html#assignment",
    "href": "01-geodemographics.html#assignment",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "The creation of a geodemographic classification is an iterative process. This typically includes adding or removing variables, adjusting the number of clusters, and grouping data in different ways to achieve the most meaningful segmentation. If you want to refine your clustering solution, you can re-run the analysis with different variables or cluster numbers by simply updating your code. However, automating parts of this process with a function would streamline the workflow and make it more efficient.\nTry to create a simple R function that:\n\nTakes at least three arguments: a data frame containing the input data, the number of clusters you want, and a list of input variables.\nExecutes a k-means clustering on the specified input variables and number of clusters.\nGenerates a csv file that contains a table of means for each cluster in the solution.\n\n\n\n\n\n\n\n\nYour function could be structured like this: run-kmeans(df, k, vars), where df is your input dataframe, k is the number of clusters, and vars is a list of input variables.\nFor a more in-depth discussion on constructing functions in R, refer to Hadley Wickham’s R for Data Science Chapter on Functions."
  },
  {
    "objectID": "01-geodemographics.html#byl-geo",
    "href": "01-geodemographics.html#byl-geo",
    "title": "Geodemographic Classification",
    "section": "",
    "text": "Having finished this tutorial, you should now understand the basics of a geodemographic classification. In addition, you should now be able to write simple functions. That is all for this week!"
  },
  {
    "objectID": "02-network.html",
    "href": "02-network.html",
    "title": "Transport Network Analysis",
    "section": "",
    "text": "Transport Network Analysis\n\n\n\n\n\n\nThis GitHub page is receiving updates for the 2024-2025 academic year. The content for 2023-2024 has been archived and can be found here: [Link]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Principles of Spatial Analysis",
    "section": "",
    "text": "Week\nSection\nTopic\n\n\n\n\n1\nFoundational Concepts\nSpatial analysis for data science\n\n\n2\nFoundational Concepts\nGraphical representation of spatial data\n\n\n3\nFoundational Concepts\nSpatial autocorrelation\n\n\n4\nRaster data\nSuitability Mapping I\n\n\n5\nRaster data\nSuitability Mapping II\n\n\n\nReading week\nReading week\n\n\n6\nRaster data\nGeostatistics using Kriging\n\n\n7\nApplied Spatial Analysis\nGeodemographics\n\n\n8\nApplied Spatial Analysis\nTransport network analysis\n\n\n9\nSpatial models\nSpatial models I\n\n\n10\nSpatial models\nSpatial models II\n\n\n\n\n\n\n\n\n\nThis GitHub page is receiving updates for the 2024-2025 academic year. The content for 2023-2024 has been archived and can be found here: [Link]\n\n\n\n\n\n\n\n\n\n\n\nThis year’s version features the following major updates:\n\nSecond full rewrite of the workbook using Quarto.\nFully updated geodemographics content based on the London Output Area Classification.\nUpdated transport network analysis content.\n\n\n\n\n\n\n\nThis workbook is created using the Quarto publishing system. Elements of this workbook are partially partially based on and modified from:\n\nThe GEOG114: Principles of Spatial Analysis 2023-2024 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2022-2023 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2021-2022 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2020-2021 workbook by Justin van Dijk\n\nThe datasets used in this workshop contain:\n\nData from Office for National Statistics licensed under the Open Government Licence v.3.0\nOS data © Crown copyright and database right [2024]"
  },
  {
    "objectID": "index.html#major-updates",
    "href": "index.html#major-updates",
    "title": "Principles of Spatial Analysis",
    "section": "",
    "text": "This year’s version features the following major updates:\n\nSecond full rewrite of the workbook using Quarto.\nFully updated geodemographics content based on the London Output Area Classification.\nUpdated transport network analysis content."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Principles of Spatial Analysis",
    "section": "",
    "text": "This workbook is created using the Quarto publishing system. Elements of this workbook are partially partially based on and modified from:\n\nThe GEOG114: Principles of Spatial Analysis 2023-2024 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2022-2023 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2021-2022 workbook by Justin van Dijk\nThe GEOG114: Principles of Spatial Analysis 2020-2021 workbook by Justin van Dijk\n\nThe datasets used in this workshop contain:\n\nData from Office for National Statistics licensed under the Open Government Licence v.3.0\nOS data © Crown copyright and database right [2024]"
  }
]